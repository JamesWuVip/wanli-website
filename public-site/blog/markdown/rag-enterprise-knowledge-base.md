---
title: RAGæŠ€æœ¯åœ¨ä¼ä¸šçŸ¥è¯†åº“ä¸­çš„åº”ç”¨å®è·µ
slug: rag-enterprise-knowledge-base
excerpt: æ·±å…¥è§£æRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯å¦‚ä½•è§£å†³ä¼ä¸šçŸ¥è¯†åº“åº”ç”¨ç—›ç‚¹ï¼ŒåŒ…å«å®Œæ•´çš„æŠ€æœ¯æ¶æ„ã€å‘é‡æ•°æ®åº“é€‰å‹ã€æ£€ç´¢ç­–ç•¥ä¼˜åŒ–åŠçœŸå®æ¡ˆä¾‹åˆ†äº«
category: ai
categoryName: AIåº”ç”¨å¼€å‘
tags: ["RAG", "å‘é‡æ•°æ®åº“", "ä¼ä¸šçŸ¥è¯†åº“", "LangChain", "AIåº”ç”¨"]
author: æ™ºç†ç§‘æŠ€æŠ€æœ¯å›¢é˜Ÿ
date: 2024-12-28
readTime: 12åˆ†é’Ÿ
---

## ä¸€ã€ä¸ºä»€ä¹ˆä¼ä¸šçŸ¥è¯†åº“éœ€è¦RAGï¼Ÿ

ä¼ ç»Ÿçš„ä¼ä¸šçŸ¥è¯†åº“é¢ä¸´ä¸‰å¤§ç—›ç‚¹ï¼š

1. **æ£€ç´¢æ•ˆç‡ä½**ï¼šåŸºäºå…³é”®è¯çš„æœç´¢æ— æ³•ç†è§£è¯­ä¹‰ï¼Œç”¨æˆ·éœ€è¦åå¤å°è¯•ä¸åŒå…³é”®è¯
2. **çŸ¥è¯†å­¤å²›**ï¼šä¸åŒéƒ¨é—¨çš„çŸ¥è¯†åˆ†æ•£åœ¨å„ä¸ªç³»ç»Ÿä¸­ï¼Œéš¾ä»¥æ•´åˆ
3. **æ›´æ–°æ»å**ï¼šå¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†æˆªæ­¢æ—¶é—´å›ºå®šï¼Œæ— æ³•è·å–ä¼ä¸šæœ€æ–°ä¿¡æ¯

RAGï¼ˆRetrieval-Augmented Generationï¼‰æŠ€æœ¯é€šè¿‡"æ£€ç´¢+ç”Ÿæˆ"çš„æ–¹å¼ï¼Œå®Œç¾è§£å†³äº†è¿™äº›é—®é¢˜ï¼š

```
ç”¨æˆ·æé—® â†’ å‘é‡åŒ– â†’ æ£€ç´¢ç›¸å…³æ–‡æ¡£ â†’ æ³¨å…¥æç¤ºè¯ â†’ LLMç”Ÿæˆå›ç­”
```

### çœŸå®æ¡ˆä¾‹

æˆ‘ä»¬ä¸ºæŸåˆ¶é€ ä¸šä¼ä¸šæ„å»ºçš„RAGçŸ¥è¯†åº“ç³»ç»Ÿï¼Œå®ç°äº†ï¼š

- âœ… **æ£€ç´¢å‡†ç¡®ç‡æå‡è‡³92%**ï¼ˆåŸå…³é”®è¯æœç´¢ä»…60%ï¼‰
- âœ… **å¹³å‡å“åº”æ—¶é—´3ç§’**ï¼ˆäººå·¥æŸ¥æ‰¾éœ€è¦10-30åˆ†é’Ÿï¼‰
- âœ… **çŸ¥è¯†è¦†ç›–ç‡100%**ï¼ˆæ•´åˆäº†5ä¸ªä¸åŒéƒ¨é—¨çš„æ–‡æ¡£ï¼‰
- âœ… **ç”¨æˆ·æ»¡æ„åº¦ä»45%æå‡è‡³89%**

## äºŒã€RAGç³»ç»ŸæŠ€æœ¯æ¶æ„

### 2.1 æ•´ä½“æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç”¨æˆ·ç•Œé¢    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           åº”ç”¨å±‚ï¼ˆAPI Serverï¼‰           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ æŸ¥è¯¢å¤„ç†   â”‚      â”‚ æ–‡æ¡£ç®¡ç†   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‘é‡æ•°æ®åº“   â”‚    â”‚  æ–‡æ¡£å­˜å‚¨       â”‚
â”‚ (Pinecone/   â”‚    â”‚  (S3/OSS)      â”‚
â”‚  Milvus)     â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Embedding Model      â”‚
â”‚   (OpenAI/æœ¬åœ°æ¨¡å‹)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒç»„ä»¶

#### 1. æ–‡æ¡£å¤„ç†å±‚

è´Ÿè´£å°†å„ç§æ ¼å¼çš„æ–‡æ¡£è½¬æ¢ä¸ºå¯æ£€ç´¢çš„æ–‡æœ¬å—ï¼š

```python
from langchain.document_loaders import (
    PDFLoader,
    DocxLoader,
    UnstructuredMarkdownLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter

# åŠ è½½æ–‡æ¡£
loader = PDFLoader("ä¼ä¸šè§„ç« åˆ¶åº¦.pdf")
documents = loader.load()

# æ–‡æœ¬åˆ†å—ï¼ˆå…³é”®å‚æ•°ï¼‰
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,        # æ¯å—1000å­—ç¬¦
    chunk_overlap=200,      # é‡å 200å­—ç¬¦ï¼Œé¿å…è¯­ä¹‰æ–­è£‚
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", " ", ""]
)

chunks = text_splitter.split_documents(documents)
```

**åˆ†å—ç­–ç•¥ä¼˜åŒ–æŠ€å·§**ï¼š

- æŠ€æœ¯æ–‡æ¡£ï¼š`chunk_size=1500`ï¼ˆä»£ç ç¤ºä¾‹éœ€è¦å®Œæ•´æ€§ï¼‰
- æ”¿ç­–è§„ç« ï¼š`chunk_size=800`ï¼ˆæ®µè½ç‹¬ç«‹æ€§å¼ºï¼‰
- å¯¹è¯è®°å½•ï¼š`chunk_size=500`ï¼ˆä¸Šä¸‹æ–‡åˆ‡æ¢é¢‘ç¹ï¼‰

#### 2. å‘é‡åŒ–ä¸å­˜å‚¨

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Pinecone
import pinecone

# åˆå§‹åŒ–å‘é‡æ¨¡å‹
embeddings = OpenAIEmbeddings(
    model="text-embedding-ada-002",  # 1536ç»´å‘é‡
    openai_api_key="your-api-key"
)

# åˆå§‹åŒ–Pinecone
pinecone.init(
    api_key="your-pinecone-key",
    environment="us-west1-gcp"
)

# åˆ›å»ºå‘é‡ç´¢å¼•
index = pinecone.Index("enterprise-knowledge")

# æ‰¹é‡å‘é‡åŒ–å¹¶å­˜å‚¨
vectorstore = Pinecone.from_documents(
    documents=chunks,
    embedding=embeddings,
    index_name="enterprise-knowledge"
)
```

#### 3. æ£€ç´¢å±‚å®ç°

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor

# åŸºç¡€æ£€ç´¢å™¨
base_retriever = vectorstore.as_retriever(
    search_type="similarity",  # ç›¸ä¼¼åº¦æœç´¢
    search_kwargs={"k": 5}     # è¿”å›Top 5ç»“æœ
)

# é«˜çº§ï¼šä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨ï¼ˆæå–æœ€ç›¸å…³ç‰‡æ®µï¼‰
compressor = LLMChainExtractor.from_llm(llm)
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=base_retriever
)

# æ‰§è¡Œæ£€ç´¢
query = "å…¬å¸çš„å¹´å‡æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ"
relevant_docs = compression_retriever.get_relevant_documents(query)
```

#### 4. ç”Ÿæˆå±‚é›†æˆ

```python
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

# åˆå§‹åŒ–LLM
llm = ChatOpenAI(
    model="gpt-4",
    temperature=0.2,  # é™ä½æ¸©åº¦ï¼Œæé«˜å‡†ç¡®æ€§
    max_tokens=1000
)

# åˆ›å»ºé—®ç­”é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",  # å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£ç›´æ¥å¡å…¥æç¤ºè¯
    retriever=compression_retriever,
    return_source_documents=True  # è¿”å›æ¥æºæ–‡æ¡£
)

# æ‰§è¡Œé—®ç­”
result = qa_chain({"query": query})

print("å›ç­”:", result["result"])
print("æ¥æºæ–‡æ¡£:", result["source_documents"])
```

## ä¸‰ã€å‘é‡æ•°æ®åº“é€‰å‹å¯¹æ¯”

| æ•°æ®åº“ | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ |
|--------|------|------|----------|
| **Pinecone** | â€¢ å…¨æ‰˜ç®¡ï¼Œæ— éœ€è¿ç»´<br>â€¢ æ€§èƒ½æä½³<br>â€¢ å®æ—¶æ›´æ–° | â€¢ æˆæœ¬è¾ƒé«˜<br>â€¢ æ•°æ®å­˜å‚¨åœ¨äº‘ç«¯ | ä¸­å°å‹ä¼ä¸š<br>å¿«é€Ÿä¸Šçº¿é¡¹ç›® |
| **Milvus** | â€¢ å¼€æºå…è´¹<br>â€¢ æ”¯æŒæ··åˆæŸ¥è¯¢<br>â€¢ é«˜åº¦å¯å®šåˆ¶ | â€¢ éœ€è¦è‡ªå»ºè¿ç»´<br>â€¢ å­¦ä¹ æ›²çº¿é™¡ | å¤§å‹ä¼ä¸š<br>å¯¹æ•°æ®å®‰å…¨è¦æ±‚é«˜ |
| **Qdrant** | â€¢ Rustç¼–å†™ï¼Œæ€§èƒ½å¥½<br>â€¢ æ”¯æŒè¿‡æ»¤æ¡ä»¶<br>â€¢ éƒ¨ç½²ç®€å• | â€¢ ç”Ÿæ€ç›¸å¯¹å°<br>â€¢ æ–‡æ¡£è¾ƒå°‘ | ä¸­å°å‹é¡¹ç›®<br>æœ¬åœ°åŒ–éƒ¨ç½² |
| **Weaviate** | â€¢ æ”¯æŒå¤šæ¨¡æ€<br>â€¢ GraphQLæŸ¥è¯¢<br>â€¢ æ¨¡å—åŒ–æ¶æ„ | â€¢ èµ„æºå ç”¨å¤§<br>â€¢ å¤æ‚åº¦é«˜ | å¤šæ¨¡æ€åº”ç”¨<br>å¤æ‚çŸ¥è¯†å›¾è°± |

### æˆ‘ä»¬çš„é€‰å‹å»ºè®®

**åœºæ™¯1ï¼šå¿«é€ŸéªŒè¯POC**
```
Pinecone + OpenAI Embeddings
ä¼˜åŠ¿ï¼š3å¤©å†…ä¸Šçº¿ï¼Œæˆæœ¬å¯æ§ï¼ˆ$70/æœˆèµ·ï¼‰
```

**åœºæ™¯2ï¼šå¤§è§„æ¨¡ä¼ä¸šéƒ¨ç½²**
```
Milvus + æœ¬åœ°Embeddingæ¨¡å‹ï¼ˆå¦‚bge-large-zhï¼‰
ä¼˜åŠ¿ï¼šæ•°æ®ç§æœ‰åŒ–ï¼Œé•¿æœŸæˆæœ¬ä½
```

**åœºæ™¯3ï¼šé¢„ç®—æœ‰é™çš„åˆåˆ›å›¢é˜Ÿ**
```
ChromaDBï¼ˆå¼€æºå†…å­˜æ•°æ®åº“ï¼‰+ OpenAI Embeddings
ä¼˜åŠ¿ï¼šå®Œå…¨å…è´¹ï¼Œå•æœºå³å¯è¿è¡Œ
```

## å››ã€æ£€ç´¢è´¨é‡ä¼˜åŒ–å®æˆ˜

### 4.1 æ··åˆæ£€ç´¢ç­–ç•¥

å•çº¯çš„å‘é‡æ£€ç´¢å¯èƒ½ä¸¢å¤±å…³é”®è¯åŒ¹é…ï¼Œæ¨èä½¿ç”¨æ··åˆæ£€ç´¢ï¼š

```python
from langchain.retrievers import EnsembleRetriever
from langchain.retrievers import BM25Retriever

# BM25å…³é”®è¯æ£€ç´¢
bm25_retriever = BM25Retriever.from_documents(chunks)
bm25_retriever.k = 3

# å‘é‡æ£€ç´¢
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# æ··åˆæ£€ç´¢ï¼ˆæƒé‡é…æ¯”ï¼‰
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, vector_retriever],
    weights=[0.3, 0.7]  # 30%å…³é”®è¯ + 70%è¯­ä¹‰
)

results = ensemble_retriever.get_relevant_documents(query)
```

**æ•ˆæœå¯¹æ¯”**ï¼š

| æ£€ç´¢æ–¹å¼ | å‡†ç¡®ç‡ | å¬å›ç‡ | å“åº”æ—¶é—´ |
|----------|--------|--------|----------|
| çº¯å…³é”®è¯ï¼ˆBM25ï¼‰ | 62% | 58% | 150ms |
| çº¯å‘é‡æ£€ç´¢ | 78% | 85% | 320ms |
| **æ··åˆæ£€ç´¢** | **89%** | **91%** | 280ms |

### 4.2 é‡æ’åºï¼ˆRerankingï¼‰

æ£€ç´¢åå¯¹ç»“æœé‡æ–°æ’åºï¼Œæå‡Top 1çš„å‡†ç¡®æ€§ï¼š

```python
from langchain.retrievers.document_compressors import CohereRerank

# ä½¿ç”¨Cohere Rerank API
reranker = CohereRerank(
    cohere_api_key="your-cohere-key",
    top_n=3  # ä»5ä¸ªå€™é€‰ä¸­é€‰å‡ºæœ€ç›¸å…³çš„3ä¸ª
)

# åº”ç”¨é‡æ’åº
rerank_retriever = ContextualCompressionRetriever(
    base_compressor=reranker,
    base_retriever=ensemble_retriever
)
```

**å®æµ‹æ•ˆæœ**ï¼š

- Top 1å‡†ç¡®ç‡ï¼š73% â†’ 91%ï¼ˆæå‡18ä¸ªç™¾åˆ†ç‚¹ï¼‰
- ç”¨æˆ·æ»¡æ„åº¦ï¼š79% â†’ 94%

### 4.3 å…ƒæ•°æ®è¿‡æ»¤

ä¸ºæ–‡æ¡£æ·»åŠ å…ƒæ•°æ®ï¼Œæ”¯æŒç²¾ç¡®è¿‡æ»¤ï¼š

```python
# æ·»åŠ å…ƒæ•°æ®
documents = [
    Document(
        page_content="...",
        metadata={
            "department": "HR",      # éƒ¨é—¨
            "doc_type": "policy",    # æ–‡æ¡£ç±»å‹
            "version": "2024-v1",    # ç‰ˆæœ¬
            "access_level": "public" # æƒé™çº§åˆ«
        }
    )
]

# å¸¦è¿‡æ»¤æ¡ä»¶çš„æ£€ç´¢
retriever = vectorstore.as_retriever(
    search_kwargs={
        "k": 5,
        "filter": {
            "department": "HR",
            "access_level": "public"
        }
    }
)
```

## äº”ã€æç¤ºè¯å·¥ç¨‹ä¼˜åŒ–

### 5.1 ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿

```python
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼ä¸šçŸ¥è¯†åº“åŠ©æ‰‹ã€‚

**è§’è‰²å®šä½**ï¼š
- åŸºäºæä¾›çš„ä¼ä¸šæ–‡æ¡£å›ç­”é—®é¢˜
- å‡†ç¡®å¼•ç”¨æ¥æºä¿¡æ¯
- æ˜ç¡®åŒºåˆ†ç¡®å®šæ€§çŸ¥è¯†å’Œæ¨æµ‹æ€§å»ºè®®

**å›ç­”è§„èŒƒ**ï¼š
1. å¦‚æœæ–‡æ¡£ä¸­æœ‰æ˜ç¡®ç­”æ¡ˆï¼Œç›´æ¥å¼•ç”¨å¹¶æ³¨æ˜æ¥æº
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·
3. ä¸è¦ç¼–é€ æˆ–çŒœæµ‹ä¿¡æ¯
4. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€

**å‚è€ƒæ–‡æ¡£**ï¼š
{context}

**ç”¨æˆ·é—®é¢˜**ï¼š
{question}

è¯·åŸºäºä»¥ä¸Šæ–‡æ¡£å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·å›å¤ï¼š"æŠ±æ­‰ï¼Œåœ¨å½“å‰çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œå»ºè®®æ‚¨è”ç³»[ç›¸å…³éƒ¨é—¨]è·å–å¸®åŠ©ã€‚"
"""
```

### 5.2 Few-Shotç¤ºä¾‹

```python
FEW_SHOT_EXAMPLES = [
    {
        "question": "å…¬å¸çš„å¹´å‡å¤©æ•°æ˜¯å¤šå°‘ï¼Ÿ",
        "answer": "æ ¹æ®ã€Šå‘˜å·¥æ‰‹å†Œã€‹ç¬¬3.2æ¡è§„å®šï¼š\n- å·¥ä½œæ»¡1å¹´ï¼š5å¤©\n- å·¥ä½œæ»¡3å¹´ï¼š10å¤©\n- å·¥ä½œæ»¡5å¹´ï¼š15å¤©\n\næ¥æºï¼šå‘˜å·¥æ‰‹å†Œv2024.pdfï¼Œç¬¬12é¡µ"
    },
    {
        "question": "å¦‚ä½•ç”³è¯·å‡ºå·®è¡¥è´´ï¼Ÿ",
        "answer": "å‡ºå·®è¡¥è´´ç”³è¯·æµç¨‹ï¼š\n1. åœ¨OAç³»ç»Ÿæäº¤å‡ºå·®ç”³è¯·\n2. ä¸Šä¼ ç¥¨æ®å‡­è¯\n3. éƒ¨é—¨ä¸»ç®¡å®¡æ‰¹\n4. è´¢åŠ¡éƒ¨å®¡æ ¸\n5. 3ä¸ªå·¥ä½œæ—¥å†…åˆ°è´¦\n\næ¥æºï¼šè´¢åŠ¡ç®¡ç†åˆ¶åº¦.docx"
    }
]
```

## å…­ã€æˆæœ¬ä¼˜åŒ–æ–¹æ¡ˆ

### 6.1 Embeddingæ¨¡å‹æˆæœ¬å¯¹æ¯”

| æ–¹æ¡ˆ | æˆæœ¬ | æ€§èƒ½ | æ¨èåœºæ™¯ |
|------|------|------|----------|
| OpenAI text-embedding-ada-002 | $0.0001/1K tokens | 1536ç»´ï¼Œä¼˜ç§€ | è‹±æ–‡ä¸ºä¸» |
| OpenAI text-embedding-3-small | $0.00002/1K tokens | 1536ç»´ï¼Œæ€§ä»·æ¯”é«˜ | **æ¨è** |
| æœ¬åœ°bge-large-zh-v1.5 | å…è´¹ï¼ˆGPUæˆæœ¬ï¼‰ | 1024ç»´ï¼Œä¸­æ–‡ä¼˜ç§€ | å¤§é‡æ•°æ® |
| æœ¬åœ°m3e-base | å…è´¹ | 768ç»´ï¼Œä¸­ç­‰ | é¢„ç®—æœ‰é™ |

**æˆæœ¬ä¼˜åŒ–ç­–ç•¥**ï¼š

```python
# æ–¹æ¡ˆ1ï¼šåˆ†å±‚å­˜å‚¨ï¼ˆå†·çƒ­æ•°æ®åˆ†ç¦»ï¼‰
def get_embeddings(text, is_hot_data=True):
    if is_hot_data:
        # é«˜é¢‘è®¿é—®æ•°æ®ä½¿ç”¨é«˜è´¨é‡embedding
        return openai_embeddings.embed_query(text)
    else:
        # ä½é¢‘æ•°æ®ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        return local_embeddings.embed_query(text)

# æ–¹æ¡ˆ2ï¼šç¼“å­˜å¸¸è§æŸ¥è¯¢
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_cached_answer(query):
    return qa_chain({"query": query})
```

**å®é™…æ”¶ç›Š**ï¼š

æŸä¼ä¸šçŸ¥è¯†åº“ï¼ˆ10ä¸‡æ–‡æ¡£ï¼‰çš„æˆæœ¬ä¼˜åŒ–ï¼š

- ä¼˜åŒ–å‰ï¼š$850/æœˆï¼ˆå…¨é‡OpenAI Embeddingï¼‰
- ä¼˜åŒ–åï¼š$120/æœˆï¼ˆæ··åˆæ–¹æ¡ˆ + ç¼“å­˜ï¼‰
- **èŠ‚çœ86%æˆæœ¬**

### 6.2 LLMè°ƒç”¨ä¼˜åŒ–

```python
from langchain.cache import RedisCache
import redis

# å¯ç”¨LLMå“åº”ç¼“å­˜
redis_client = redis.Redis(host='localhost', port=6379)
langchain.llm_cache = RedisCache(redis_client)

# è‡ªåŠ¨ç¼“å­˜ç›¸ä¼¼é—®é¢˜çš„å›ç­”
# "å…¬å¸å¹´å‡å¤šå°‘å¤©" å’Œ "å¹´å‡æœ‰å‡ å¤©" ä¼šå…±äº«ç¼“å­˜
```

## ä¸ƒã€å®é™…æ¡ˆä¾‹åˆ†äº«

### æ¡ˆä¾‹ï¼šæŸæ•™è‚²æœºæ„æ•™ç ”çŸ¥è¯†åº“

**èƒŒæ™¯**ï¼š
- 2000+åæ•™å¸ˆ
- 30ä¸‡ä»½æ•™æ¡ˆã€è¯¾ä»¶ã€è¯•å·
- åŸæ£€ç´¢ç³»ç»Ÿæ»¡æ„åº¦ä»…41%

**å®æ–½æ–¹æ¡ˆ**ï¼š

```python
# 1. æ–‡æ¡£é¢„å¤„ç†
from langchain.document_loaders import DirectoryLoader

loader = DirectoryLoader(
    "æ•™ç ”èµ„æ–™/",
    glob="**/*.{pdf,docx,pptx}",
    show_progress=True
)

# 2. æ™ºèƒ½åˆ†å—ï¼ˆä¿ç•™PPTé¡µç ã€PDFç« èŠ‚ä¿¡æ¯ï¼‰
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1200,
    chunk_overlap=300,
    add_start_index=True  # ä¿ç•™åŸå§‹ä½ç½®ä¿¡æ¯
)

# 3. å…ƒæ•°æ®å¢å¼º
for doc in documents:
    doc.metadata.update({
        "subject": extract_subject(doc),    # AIè¯†åˆ«ç§‘ç›®
        "grade": extract_grade(doc),        # å¹´çº§
        "difficulty": analyze_difficulty(doc) # éš¾åº¦
    })

# 4. å¤šæ¨¡æ€æ”¯æŒï¼ˆPPTå›¾ç‰‡æå–ï¼‰
from langchain.document_loaders import UnstructuredPPTXLoader
ppt_loader = UnstructuredPPTXLoader(
    "è¯¾ä»¶.pptx",
    mode="elements",  # æå–æ–‡å­—+å›¾ç‰‡
    strategy="hi_res"  # é«˜ç²¾åº¦OCR
)
```

**å®æ–½æ•ˆæœ**ï¼š

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| æ£€ç´¢å‡†ç¡®ç‡ | 58% | 94% | +62% |
| å¹³å‡æ£€ç´¢æ—¶é—´ | 8åˆ†é’Ÿ | 5ç§’ | -99.9% |
| ç”¨æˆ·æ»¡æ„åº¦ | 41% | 93% | +127% |
| çŸ¥è¯†å¤ç”¨ç‡ | 23% | 78% | +239% |

**ROIåˆ†æ**ï¼š

- å¼€å‘æˆæœ¬ï¼šÂ¥18ä¸‡
- å¹´èŠ‚çœäººåŠ›æˆæœ¬ï¼šÂ¥65ä¸‡ï¼ˆæ•™å¸ˆæ£€ç´¢æ—¶é—´å‡å°‘ï¼‰
- æŠ•èµ„å›æŠ¥å‘¨æœŸï¼š3.3ä¸ªæœˆ

## å…«ã€å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### Q1: å‘é‡æ£€ç´¢å¬å›ç‡ä½æ€ä¹ˆåŠï¼Ÿ

**åŸå› åˆ†æ**ï¼š
- chunk_sizeè®¾ç½®ä¸åˆç†
- queryå’Œæ–‡æ¡£çš„è¡¨è¿°å·®å¼‚å¤§
- embeddingæ¨¡å‹ä¸é€‚åˆä¸šåŠ¡é¢†åŸŸ

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# 1. Queryæ”¹å†™ï¼ˆæ‰©å±•ç”¨æˆ·é—®é¢˜ï¼‰
from langchain.chains import LLMChain

query_rewrite_prompt = """
å°†ç”¨æˆ·çš„ç®€çŸ­é—®é¢˜æ‰©å±•ä¸ºæ›´è¯¦ç»†çš„è¡¨è¿°ï¼Œå¢åŠ æ£€ç´¢å¬å›ç‡ã€‚

åŸé—®é¢˜: {query}
æ‰©å±•å:
"""

rewriter = LLMChain(llm=llm, prompt=query_rewrite_prompt)
expanded_query = rewriter.run(query="å¹´å‡å‡ å¤©ï¼Ÿ")
# è¾“å‡º: "è¯·é—®å…¬å¸å‘˜å·¥çš„å¹´å‡å¤©æ•°æ˜¯å¤šå°‘ï¼Ÿä¸åŒå·¥é¾„çš„å¹´å‡æ”¿ç­–æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
```

### Q2: å›ç­”ä¸å‡†ç¡®ï¼Œç»å¸¸å‡ºç°å¹»è§‰ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# å¼ºåŒ–æç¤ºè¯çº¦æŸ
STRICT_PROMPT = """
**é‡è¦çº¦æŸ**ï¼š
1. åªèƒ½ä½¿ç”¨æä¾›çš„æ–‡æ¡£ä¸­çš„ä¿¡æ¯
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®ç­”æ¡ˆï¼Œå¿…é¡»å›å¤"æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
3. ç¦æ­¢ä½¿ç”¨æ¨¡å‹çš„é¢„è®­ç»ƒçŸ¥è¯†
4. æ¯ä¸ªå…³é”®ä¿¡æ¯å¿…é¡»æ ‡æ³¨æ¥æº

å‚è€ƒæ–‡æ¡£: {context}
é—®é¢˜: {question}

å›ç­”æ ¼å¼ï¼š
[ç­”æ¡ˆå†…å®¹]

æ¥æºï¼š[æ–‡æ¡£åç§°ï¼Œç¬¬Xé¡µ/ç¬¬Xæ¡]
"""
```

### Q3: å“åº”é€Ÿåº¦æ…¢ï¼ˆ>5ç§’ï¼‰ï¼Ÿ

**ä¼˜åŒ–æ‰‹æ®µ**ï¼š

```python
# 1. å¼‚æ­¥å¤„ç†
import asyncio
from langchain.callbacks import AsyncCallbackHandler

async def async_qa(query):
    result = await qa_chain.acall({"query": query})
    return result

# 2. æµå¼è¾“å‡ºï¼ˆæ”¹å–„ç”¨æˆ·ä½“éªŒï¼‰
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

llm = ChatOpenAI(
    streaming=True,
    callbacks=[StreamingStdOutCallbackHandler()]
)

# 3. é¢„æ£€ç´¢ç¼“å­˜çƒ­é—¨é—®é¢˜
POPULAR_QUERIES = ["å¹´å‡", "æŠ¥é”€", "è€ƒå‹¤", ...]
for q in POPULAR_QUERIES:
    qa_chain({"query": q})  # é¢„çƒ­ç¼“å­˜
```

## ä¹ã€æ€»ç»“ä¸æœ€ä½³å®è·µ

### æ ¸å¿ƒè¦ç‚¹

1. **æ–‡æ¡£é¢„å¤„ç†æ˜¯å…³é”®**
   - æ¸…ç†å™ªå£°ï¼ˆé¡µçœ‰é¡µè„šã€æ°´å°ï¼‰
   - ä¿ç•™ç»“æ„ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼ï¼‰
   - åˆç†åˆ†å—ï¼ˆé¿å…è¯­ä¹‰æ–­è£‚ï¼‰

2. **é€‰æ‹©åˆé€‚çš„å‘é‡æ•°æ®åº“**
   - å°é¡¹ç›®ï¼šChromaDB / Pinecone
   - å¤§é¡¹ç›®ï¼šMilvus / Weaviate
   - è€ƒè™‘æ•°æ®å®‰å…¨ã€æˆæœ¬ã€è¿ç»´éš¾åº¦

3. **æ··åˆæ£€ç´¢ç­–ç•¥**
   - å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç†è§£ï¼‰
   - å…³é”®è¯æ£€ç´¢ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
   - é‡æ’åºï¼ˆæå‡Top 1ï¼‰

4. **æç¤ºè¯å·¥ç¨‹**
   - æ˜ç¡®è§’è‰²å®šä½
   - æ·»åŠ Few-Shotç¤ºä¾‹
   - å¼ºåŒ–çº¦æŸæ¡ä»¶

5. **æŒç»­ä¼˜åŒ–**
   - æ”¶é›†badcase
   - A/Bæµ‹è¯•ä¸åŒç­–ç•¥
   - ç›‘æ§æ ¸å¿ƒæŒ‡æ ‡

### æ¨èå·¥å…·é“¾

```
æ–‡æ¡£å¤„ç†: Unstructured + LangChain
å‘é‡æ¨¡å‹: OpenAI text-embedding-3-small (è‹±æ–‡)
         bge-large-zh-v1.5 (ä¸­æ–‡)
å‘é‡æ•°æ®åº“: Pinecone (æ‰˜ç®¡) / Milvus (è‡ªå»º)
LLM: GPT-4 (é«˜è´¨é‡) / GPT-3.5-turbo (æ€§ä»·æ¯”)
æ¡†æ¶: LangChain / LlamaIndex
```

---

## å…³äºæˆ‘ä»¬

æ™ºç†ç§‘æŠ€ä¸“æ³¨äºä¼ä¸šçº§AIåº”ç”¨å¼€å‘ï¼Œæˆ‘ä»¬å·²ä¸º20+ä¼ä¸šæˆåŠŸéƒ¨ç½²RAGçŸ¥è¯†åº“ç³»ç»Ÿã€‚

**æœåŠ¡å†…å®¹**ï¼š
- éœ€æ±‚åˆ†æä¸æŠ€æœ¯é€‰å‹
- POCå¿«é€ŸéªŒè¯ï¼ˆ2å‘¨ï¼‰
- å®Œæ•´ç³»ç»Ÿå¼€å‘ä¸éƒ¨ç½²
- æŒç»­ä¼˜åŒ–ä¸è¿ç»´æ”¯æŒ

**è”ç³»æˆ‘ä»¬**ï¼š
- ğŸ“§ é‚®ç®±: wuning@wanli.ai
- ğŸŒ å®˜ç½‘: https://zhili.wanli.ai
- ğŸ“ æŠ€æœ¯åšå®¢: https://zhili.wanli.ai/blog/

æ¬¢è¿äº¤æµæ¢è®¨ä¼ä¸šçŸ¥è¯†åº“å»ºè®¾ç»éªŒï¼
