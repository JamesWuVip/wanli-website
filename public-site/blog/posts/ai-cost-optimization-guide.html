<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AIåº”ç”¨æˆæœ¬ä¼˜åŒ–å®Œå…¨æŒ‡å—ï¼šä»æ¯æœˆ$5000é™è‡³$800çš„å®æˆ˜ç»éªŒ - æ™ºç†ç§‘æŠ€æŠ€æœ¯åšå®¢</title>
    <meta name="description" content="åˆ†äº«çœŸå®é¡¹ç›®ä¸­å°†AIåº”ç”¨æˆæœ¬ä»æ¯æœˆ$5000é™è‡³$800çš„å®Œæ•´ä¼˜åŒ–ç­–ç•¥ï¼Œæ¶µç›–æ¨¡å‹é€‰å‹ã€Promptä¼˜åŒ–ã€ç¼“å­˜ç­–ç•¥ã€æœ¬åœ°åŒ–éƒ¨ç½²ç­‰å¤šä¸ªç»´åº¦">
    <meta name="keywords" content="æˆæœ¬ä¼˜åŒ–,AIåº”ç”¨,GPT-4,å¼€æºæ¨¡å‹,æ€§èƒ½ä¼˜åŒ–">
    <meta name="author" content="æ™ºç†ç§‘æŠ€æŠ€æœ¯å›¢é˜Ÿ">
    <link rel="canonical" href="https://zhili.wanli.ai/blog/posts/ai-cost-optimization-guide.html">

    <!-- Open Graph -->
    <meta property="og:title" content="AIåº”ç”¨æˆæœ¬ä¼˜åŒ–å®Œå…¨æŒ‡å—ï¼šä»æ¯æœˆ$5000é™è‡³$800çš„å®æˆ˜ç»éªŒ">
    <meta property="og:description" content="åˆ†äº«çœŸå®é¡¹ç›®ä¸­å°†AIåº”ç”¨æˆæœ¬ä»æ¯æœˆ$5000é™è‡³$800çš„å®Œæ•´ä¼˜åŒ–ç­–ç•¥ï¼Œæ¶µç›–æ¨¡å‹é€‰å‹ã€Promptä¼˜åŒ–ã€ç¼“å­˜ç­–ç•¥ã€æœ¬åœ°åŒ–éƒ¨ç½²ç­‰å¤šä¸ªç»´åº¦">
    <meta property="og:image" content="https://zhili.wanli.ai/og-image.jpg">
    <meta property="og:url" content="https://zhili.wanli.ai/blog/posts/ai-cost-optimization-guide.html">
    <meta property="og:type" content="article">
    <meta property="article:published_time" content="2024-12-31T10:00:00+08:00">
    <meta property="article:author" content="æ™ºç†ç§‘æŠ€æŠ€æœ¯å›¢é˜Ÿ">
    <meta property="article:section" content="AIåº”ç”¨å¼€å‘">
    <meta property="article:tag" content="æˆæœ¬ä¼˜åŒ–">
    <meta property="article:tag" content="AIåº”ç”¨">
    <meta property="article:tag" content="GPT-4">
    <meta property="article:tag" content="å¼€æºæ¨¡å‹">
    <meta property="article:tag" content="æ€§èƒ½ä¼˜åŒ–">

    <!-- BreadcrumbList ç»“æ„åŒ–æ•°æ® -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "BreadcrumbList",
      "itemListElement": [
        {"@type": "ListItem", "position": 1, "name": "é¦–é¡µ", "item": "https://zhili.wanli.ai"},
        {"@type": "ListItem", "position": 2, "name": "æŠ€æœ¯åšå®¢", "item": "https://zhili.wanli.ai/blog/"},
        {"@type": "ListItem", "position": 3, "name": "AIåº”ç”¨æˆæœ¬ä¼˜åŒ–å®Œå…¨æŒ‡å—"}
      ]
    }
    </script>

    <!-- Tailwind CSS -->
    <link rel="stylesheet" href="/css/tailwind.min.css">

    <!-- ç™¾åº¦ç»Ÿè®¡ -->
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?899d2895125d00f40d4e27a4e9490d14";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-HYYQPK3KW2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-HYYQPK3KW2');
    </script>

    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif, "Microsoft YaHei";
        }

        .prose {
            max-width: 800px;
            margin: 0 auto;
            color: #374151;
        }

        .prose h2 {
            font-size: 1.875rem;
            font-weight: 700;
            margin-top: 3rem;
            margin-bottom: 1rem;
            color: #111827;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #e5e7eb;
        }

        .prose h3 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 2rem;
            margin-bottom: 0.75rem;
            color: #1f2937;
        }

        .prose h4 {
            font-size: 1.25rem;
            font-weight: 600;
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
            color: #374151;
        }

        .prose p {
            margin-bottom: 1.25rem;
            line-height: 1.75;
            color: #4b5563;
        }

        .prose ul, .prose ol {
            margin-bottom: 1.25rem;
            padding-left: 1.5rem;
        }

        .prose li {
            margin-bottom: 0.5rem;
            color: #4b5563;
            line-height: 1.75;
        }

        .prose code {
            background: #f3f4f6;
            padding: 0.2rem 0.4rem;
            border-radius: 0.25rem;
            font-family: 'SF Mono', 'Monaco', 'Cascadia Code', 'Courier New', monospace;
            color: #dc2626;
            font-size: 0.875em;
        }

        .prose pre {
            background: #1f2937;
            padding: 1.5rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            border: 1px solid #374151;
        }

        .prose pre code {
            background: transparent;
            padding: 0;
            color: #e5e7eb;
            font-size: 0.875rem;
        }

        .prose a {
            color: #2563eb;
            text-decoration: none;
            border-bottom: 1px solid transparent;
            transition: border-color 0.2s;
        }

        .prose a:hover {
            border-bottom-color: #2563eb;
        }

        .prose strong {
            font-weight: 600;
            color: #111827;
        }

        .prose blockquote {
            border-left: 4px solid #2563eb;
            padding-left: 1.5rem;
            margin: 1.5rem 0;
            color: #6b7280;
            font-style: italic;
        }

        .prose table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
        }

        .prose th {
            background: #f9fafb;
            border: 1px solid #e5e7eb;
            padding: 0.75rem;
            text-align: left;
            font-weight: 600;
            color: #111827;
        }

        .prose td {
            border: 1px solid #e5e7eb;
            padding: 0.75rem;
            color: #4b5563;
        }

        .prose tr:nth-child(even) {
            background: #f9fafb;
        }

        .prose img {
            max-width: 100%;
            border-radius: 0.5rem;
            margin: 1.5rem 0;
        }

        .category-badge {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .category-ai { background: #dbeafe; color: #1e40af; }
        .category-architecture { background: #fce7f3; color: #9f1239; }
        .category-system { background: #dcfce7; color: #166534; }
        .category-case { background: #fef3c7; color: #92400e; }

        .tag {
            display: inline-block;
            padding: 4px 12px;
            background: #f3f4f6;
            color: #6b7280;
            border-radius: 4px;
            font-size: 0.875rem;
            margin-right: 8px;
            margin-bottom: 8px;
        }

        .contact-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 0.75rem;
            padding: 2rem;
            margin: 2rem 0;
        }

        .nav-link {
            position: relative;
            padding-bottom: 4px;
        }

        .nav-link::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 0;
            height: 2px;
            background: #2563eb;
            transition: width 0.3s;
        }

        .nav-link:hover::after {
            width: 100%;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-900">

    <!-- å¯¼èˆªæ  -->
    <nav class="bg-white border-b border-gray-200 sticky top-0 z-50">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex justify-between items-center h-16">
                <a href="/" class="text-xl font-bold text-gray-900 hover:text-blue-600 transition">
                    æ™ºç†ç§‘æŠ€
                </a>
                <div class="flex gap-8">
                    <a href="/" class="nav-link text-gray-600 hover:text-gray-900 transition">é¦–é¡µ</a>
                    <a href="/blog/" class="nav-link text-blue-600 font-medium">åšå®¢</a>
                    <a href="/#contact" class="nav-link text-gray-600 hover:text-gray-900 transition">è”ç³»æˆ‘ä»¬</a>
                </div>
            </div>
        </div>
    </nav>

    <!-- æ–‡ç« å†…å®¹ -->
    <main class="py-12">
        <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">

            <!-- æ–‡ç« å¤´éƒ¨ -->
            <header class="mb-12">
                <div class="mb-6">
                    <a href="/blog/" class="inline-flex items-center text-gray-600 hover:text-gray-900 text-sm">
                        <svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 19l-7-7m0 0l7-7m-7 7h18"></path>
                        </svg>
                        è¿”å›åšå®¢åˆ—è¡¨
                    </a>
                </div>
                <div class="flex items-center gap-3 mb-4">
                    <span class="category-badge category-ai">AIåº”ç”¨å¼€å‘</span>
                    <span class="text-gray-500 text-sm">2024å¹´12æœˆ31æ—¥</span>
                    <span class="text-gray-400">Â·</span>
                    <span class="text-gray-500 text-sm flex items-center">
                        <svg class="w-4 h-4 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path>
                        </svg>
                        20åˆ†é’Ÿ
                    </span>
                </div>
                <h1 class="text-4xl md:text-5xl font-bold text-gray-900 mb-4 leading-tight">
                    AIåº”ç”¨æˆæœ¬ä¼˜åŒ–å®Œå…¨æŒ‡å—ï¼šä»æ¯æœˆ$5000é™è‡³$800çš„å®æˆ˜ç»éªŒ
                </h1>
                <p class="text-xl text-gray-600 leading-relaxed">
                    åˆ†äº«çœŸå®é¡¹ç›®ä¸­å°†AIåº”ç”¨æˆæœ¬ä»æ¯æœˆ$5000é™è‡³$800çš„å®Œæ•´ä¼˜åŒ–ç­–ç•¥ï¼Œæ¶µç›–æ¨¡å‹é€‰å‹ã€Promptä¼˜åŒ–ã€ç¼“å­˜ç­–ç•¥ã€æœ¬åœ°åŒ–éƒ¨ç½²ç­‰å¤šä¸ªç»´åº¦
                </p>
            </header>

            <!-- æ–‡ç« ä¸»ä½“ -->
            <article class="prose prose-lg">
                <h2>ä¸€ã€çœŸå®æ¡ˆä¾‹ï¼šæˆæœ¬ä¼˜åŒ–ä¹‹è·¯</h2>
<h3>1.1 é¡¹ç›®èƒŒæ™¯</h3>
<p>æŸåœ¨çº¿æ•™è‚²å¹³å°çš„AIä½œæ–‡æ‰¹æ”¹ç³»ç»Ÿï¼š</p>
<p><strong>ä¸šåŠ¡æ•°æ®</strong>ï¼š</p>
<ul>
<li>æ—¥æ´»ç”¨æˆ·ï¼š8,000äºº</li>
<li>æ—¥å‡æ‰¹æ”¹æ¬¡æ•°ï¼š15,000æ¬¡</li>
<li>å¹³å‡æ¯ç¯‡ä½œæ–‡ï¼š800å­—</li>
</ul>
<p><strong>æˆæœ¬çˆ†ç‚¸</strong>ï¼ˆä¸Šçº¿ç¬¬1ä¸ªæœˆï¼‰ï¼š</p>
<pre><code>AIæˆæœ¬æ˜ç»†ï¼š
- OpenAI APIè´¹ç”¨ï¼š$4,800/æœˆ
- å‘é‡æ•°æ®åº“ï¼ˆPineconeï¼‰ï¼š$150/æœˆ
- æœåŠ¡å™¨æˆæœ¬ï¼š$200/æœˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ€»è®¡ï¼š$5,150/æœˆ

å•æ¬¡æ‰¹æ”¹æˆæœ¬ï¼š$0.34
æœˆæ”¶å…¥ï¼š$12,000ï¼ˆ120ç”¨æˆ· Ã— $100/æœˆï¼‰
æˆæœ¬å æ¯”ï¼š43%ï¼ˆä¸¥é‡äºæŸï¼‰
</code></pre>
<p><strong>è€æ¿çš„çµé­‚æ‹·é—®</strong>ï¼š</p>
<blockquote>
<p>&quot;AIè¿™ä¹ˆè´µï¼Œæˆ‘ä»¬è¿˜è¦ä¸è¦åšä¸‹å»ï¼Ÿ&quot;</p>
</blockquote>
<h3>1.2 ä¼˜åŒ–åçš„æˆæœ</h3>
<p>ç»è¿‡2ä¸ªæœˆçš„ç³»ç»Ÿä¼˜åŒ–ï¼š</p>
<pre><code>ä¼˜åŒ–åæˆæœ¬ï¼š
- OpenAI APIï¼š$450/æœˆï¼ˆ-91%ï¼‰
- æœ¬åœ°æ¨¡å‹æ¨ç†ï¼š$200/æœˆï¼ˆGPUæœåŠ¡å™¨ï¼‰
- å‘é‡æ•°æ®åº“ï¼š$0ï¼ˆæ”¹ç”¨è‡ªå»ºQdrantï¼‰
- æœåŠ¡å™¨æˆæœ¬ï¼š$150/æœˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ€»è®¡ï¼š$800/æœˆï¼ˆ-84.5%ï¼‰

å•æ¬¡æ‰¹æ”¹æˆæœ¬ï¼š$0.053ï¼ˆ-84%)
æˆæœ¬å æ¯”ï¼š6.7%ï¼ˆå¥åº·æ°´å¹³ï¼‰
</code></pre>
<p><strong>å¦‚ä½•åšåˆ°çš„ï¼Ÿ</strong> è®©æˆ‘ä»¬é€æ­¥æ‹†è§£ã€‚</p>
<h2>äºŒã€æˆæœ¬æ„æˆåˆ†æ</h2>
<h3>2.1 AIæˆæœ¬çš„å†°å±±æ¨¡å‹</h3>
<pre><code>å¯è§æˆæœ¬ï¼ˆ40%ï¼‰:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI APIç›´æ¥è´¹ç”¨     â”‚  â† å¤§å®¶å…³æ³¨çš„
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

éšè—æˆæœ¬ï¼ˆ60%ï¼‰:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¤±è´¥é‡è¯•ï¼ˆ15%ï¼‰        â”‚
â”‚  Promptå†—ä½™ï¼ˆ20%ï¼‰      â”‚
â”‚  ç¼“å­˜ç¼ºå¤±ï¼ˆ10%ï¼‰        â”‚
â”‚  æ¨¡å‹é€‰å‹ä¸å½“ï¼ˆ15%ï¼‰    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>2.2 æˆæœ¬è®¡ç®—å…¬å¼</h3>
<p><strong>OpenAI APIå®šä»·</strong>ï¼ˆ2024å¹´12æœˆï¼‰ï¼š</p>
<table>
<thead>
<tr>
<th>æ¨¡å‹</th>
<th>Inputä»·æ ¼</th>
<th>Outputä»·æ ¼</th>
<th>ä¸Šä¸‹æ–‡é•¿åº¦</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-4 Turbo</td>
<td>$10/1M tokens</td>
<td>$30/1M tokens</td>
<td>128K</td>
</tr>
<tr>
<td>GPT-4</td>
<td>$30/1M tokens</td>
<td>$60/1M tokens</td>
<td>8K</td>
</tr>
<tr>
<td>GPT-3.5 Turbo</td>
<td>$0.50/1M tokens</td>
<td>$1.50/1M tokens</td>
<td>16K</td>
</tr>
<tr>
<td>GPT-3.5 Turbo 16k</td>
<td>$3/1M tokens</td>
<td>$4/1M tokens</td>
<td>16K</td>
</tr>
</tbody></table>
<p><strong>å®é™…æˆæœ¬è®¡ç®—</strong>ï¼š</p>
<pre><code class="language-python">def calculate_cost(prompt_tokens, completion_tokens, model=&quot;gpt-4-turbo&quot;):
    pricing = {
        &quot;gpt-4-turbo&quot;: {&quot;input&quot;: 0.01, &quot;output&quot;: 0.03},
        &quot;gpt-3.5-turbo&quot;: {&quot;input&quot;: 0.0005, &quot;output&quot;: 0.0015}
    }

    input_cost = (prompt_tokens / 1000) * pricing[model][&quot;input&quot;]
    output_cost = (completion_tokens / 1000) * pricing[model][&quot;output&quot;]

    return input_cost + output_cost

# ç¤ºä¾‹ï¼šä½œæ–‡æ‰¹æ”¹
prompt_tokens = 2000  # System prompt + ä½œæ–‡å†…å®¹
completion_tokens = 800  # AIæ‰¹æ”¹ç»“æœ

cost_gpt4 = calculate_cost(2000, 800, &quot;gpt-4-turbo&quot;)
cost_gpt35 = calculate_cost(2000, 800, &quot;gpt-3.5-turbo&quot;)

print(f&quot;GPT-4 Turbo: ${cost_gpt4:.4f}&quot;)  # $0.0440
print(f&quot;GPT-3.5 Turbo: ${cost_gpt35:.4f}&quot;)  # $0.0022
print(f&quot;æˆæœ¬å·®å¼‚: {cost_gpt4 / cost_gpt35:.1f}x&quot;)  # 20å€
</code></pre>
<h2>ä¸‰ã€ä¼˜åŒ–ç­–ç•¥ä¸€ï¼šæ™ºèƒ½æ¨¡å‹è·¯ç”±</h2>
<h3>3.1 é—®é¢˜åˆ†çº§</h3>
<p>ä¸æ˜¯æ‰€æœ‰ä»»åŠ¡éƒ½éœ€è¦GPT-4ï¼</p>
<p><strong>ä»»åŠ¡åˆ†ç±»</strong>ï¼š</p>
<pre><code>ç®€å•ä»»åŠ¡ï¼ˆ70%ï¼‰â†’ GPT-3.5 Turbo
- åŸºç¡€è¯­æ³•æ£€æŸ¥
- ç®€å•é—®ç­”
- æ ¼å¼åŒ–è¾“å‡º

ä¸­ç­‰ä»»åŠ¡ï¼ˆ25%ï¼‰â†’ GPT-4 Turbo
- å¤æ‚æ‰¹æ”¹
- æ·±åº¦åˆ†æ
- åˆ›æ„å†™ä½œ

å›°éš¾ä»»åŠ¡ï¼ˆ5%ï¼‰â†’ GPT-4 + Human
- ç–‘éš¾é—®é¢˜
- äº‰è®®å†…å®¹
- éœ€è¦ä¸“ä¸šåˆ¤æ–­
</code></pre>
<h3>3.2 å®ç°æ™ºèƒ½è·¯ç”±</h3>
<pre><code class="language-python">class ModelRouter:
    def __init__(self):
        self.gpt35 = ChatOpenAI(model=&quot;gpt-3.5-turbo&quot;)
        self.gpt4 = ChatOpenAI(model=&quot;gpt-4-turbo&quot;)

    def route_model(self, task_type, content_length, complexity_score):
        &quot;&quot;&quot;
        æ ¹æ®ä»»åŠ¡ç‰¹å¾é€‰æ‹©åˆé€‚çš„æ¨¡å‹
        &quot;&quot;&quot;
        # è§„åˆ™1ï¼šç®€å•çŸ­æ–‡æœ¬ç”¨GPT-3.5
        if content_length &lt; 500 and complexity_score &lt; 0.3:
            return self.gpt35, &quot;gpt-3.5-turbo&quot;

        # è§„åˆ™2ï¼šä¸­ç­‰å¤æ‚åº¦å…ˆè¯•GPT-3.5
        if complexity_score &lt; 0.7:
            return self.gpt35, &quot;gpt-3.5-turbo&quot;

        # è§„åˆ™3ï¼šé«˜å¤æ‚åº¦ç”¨GPT-4
        return self.gpt4, &quot;gpt-4-turbo&quot;

    def calculate_complexity(self, content):
        &quot;&quot;&quot;
        è¯„ä¼°å†…å®¹å¤æ‚åº¦ï¼ˆ0-1åˆ†ï¼‰
        &quot;&quot;&quot;
        features = {
            &#39;length&#39;: len(content),
            &#39;vocab_diversity&#39;: len(set(content.split())) / len(content.split()),
            &#39;sentence_complexity&#39;: self._avg_sentence_length(content),
            &#39;grammar_errors&#39;: self._detect_grammar_errors(content)
        }

        # åŠ æƒè®¡ç®—
        complexity = (
            features[&#39;length&#39;] / 5000 * 0.3 +
            features[&#39;vocab_diversity&#39;] * 0.3 +
            features[&#39;sentence_complexity&#39;] / 50 * 0.2 +
            features[&#39;grammar_errors&#39;] / 10 * 0.2
        )

        return min(complexity, 1.0)

# ä½¿ç”¨ç¤ºä¾‹
router = ModelRouter()

def process_essay(essay_content):
    complexity = router.calculate_complexity(essay_content)
    model, model_name = router.route_model(
        task_type=&quot;essay_grading&quot;,
        content_length=len(essay_content),
        complexity_score=complexity
    )

    response = model.invoke(essay_content)
    log_usage(model_name, response.usage)  # è®°å½•ä½¿ç”¨æƒ…å†µ

    return response
</code></pre>
<p><strong>æ•ˆæœ</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>æŒ‡æ ‡</th>
<th>ä¼˜åŒ–å‰</th>
<th>ä¼˜åŒ–å</th>
<th>æ”¹å–„</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-4ä½¿ç”¨å æ¯”</td>
<td>100%</td>
<td>18%</td>
<td>-82%</td>
</tr>
<tr>
<td>å¹³å‡æˆæœ¬</td>
<td>$0.044</td>
<td>$0.011</td>
<td>-75%</td>
</tr>
<tr>
<td>å‡†ç¡®ç‡</td>
<td>94%</td>
<td>93%</td>
<td>-1%</td>
</tr>
</tbody></table>
<p><strong>æˆæœ¬èŠ‚çœ</strong>ï¼š<code>$4,800 â†’ $1,200</code>ï¼ˆ-75%ï¼‰</p>
<h3>3.3 çº§è”é™çº§ç­–ç•¥</h3>
<pre><code class="language-python">class CascadeLLM:
    def __init__(self):
        self.models = [
            (&quot;gpt-3.5-turbo&quot;, 0.8),  # (æ¨¡å‹, ç½®ä¿¡åº¦é˜ˆå€¼)
            (&quot;gpt-4-turbo&quot;, 0.9),
            (&quot;gpt-4&quot;, 1.0)
        ]

    def process(self, query):
        &quot;&quot;&quot;
        çº§è”è°ƒç”¨ï¼šä»ä¾¿å®œæ¨¡å‹å¼€å§‹ï¼Œä¸æ»¡è¶³è¦æ±‚æ—¶å‡çº§
        &quot;&quot;&quot;
        for model_name, threshold in self.models:
            model = ChatOpenAI(model=model_name)
            response = model.invoke(query)

            # è¯„ä¼°å“åº”è´¨é‡
            confidence = self.evaluate_confidence(response)

            if confidence &gt;= threshold:
                return response  # æ»¡è¶³è¦æ±‚ï¼Œè¿”å›

            print(f&quot;{model_name} ç½®ä¿¡åº¦ä¸è¶³({confidence:.2f}), å‡çº§æ¨¡å‹...&quot;)

        return response  # æœ€åä¸€ä¸ªæ¨¡å‹çš„ç»“æœ

    def evaluate_confidence(self, response):
        &quot;&quot;&quot;
        è¯„ä¼°å“åº”è´¨é‡ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
        &quot;&quot;&quot;
        # å®é™…å¯ä»¥ç”¨ä¸“é—¨çš„è¯„ä¼°æ¨¡å‹
        keywords = [&quot;æŠ±æ­‰&quot;, &quot;ä¸ç¡®å®š&quot;, &quot;å¯èƒ½&quot;, &quot;ä¹Ÿè®¸&quot;]
        text = response.content.lower()

        if any(kw in text for kw in keywords):
            return 0.6  # ä½ç½®ä¿¡åº¦

        if len(text) &lt; 50:
            return 0.7  # å›ç­”å¤ªçŸ­

        return 0.95  # é«˜ç½®ä¿¡åº¦
</code></pre>
<p><strong>æˆæœ¬å¯¹æ¯”</strong>ï¼š</p>
<pre><code>åœºæ™¯ï¼š100æ¬¡è¯·æ±‚

çº¯GPT-4: 100æ¬¡ Ã— $0.044 = $4.40

çº§è”ç­–ç•¥:
- 70æ¬¡ç”±GPT-3.5æ»¡è¶³ â†’ 70 Ã— $0.0022 = $0.154
- 25æ¬¡å‡çº§åˆ°GPT-4 Turbo â†’ 25 Ã— $0.022 = $0.550
- 5æ¬¡å‡çº§åˆ°GPT-4 â†’ 5 Ã— $0.044 = $0.220
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ€»æˆæœ¬: $0.924ï¼ˆèŠ‚çœ79%ï¼‰
</code></pre>
<h2>å››ã€ä¼˜åŒ–ç­–ç•¥äºŒï¼šPromptå‹ç¼©</h2>
<h3>4.1 å†—ä½™åˆ†æ</h3>
<p><strong>æ¡ˆä¾‹ï¼šä½œæ–‡æ‰¹æ”¹æç¤ºè¯</strong></p>
<p><strong>ä¼˜åŒ–å‰</strong>ï¼ˆ2,800 tokensï¼‰ï¼š</p>
<pre><code>ä½ æ˜¯ä¸€ä½æ‹¥æœ‰20å¹´æ•™å­¦ç»éªŒçš„èµ„æ·±è¯­æ–‡æ•™å¸ˆï¼Œæ›¾åœ¨å¤šæ‰€é‡ç‚¹ä¸­å­¦æ‹…ä»»é«˜çº§æ•™å¸ˆï¼Œ
åŸ¹å…»äº†æ— æ•°ä¼˜ç§€å­¦ç”Ÿï¼Œå¯¹äºä½œæ–‡æ‰¹æ”¹æœ‰ç€éå¸¸ä¸°å¯Œçš„ç»éªŒå’Œç‹¬åˆ°çš„è§è§£ã€‚

ç°åœ¨ï¼Œè¯·ä½ ä»¥ä¸€ä½ä¸“ä¸šæ•™å¸ˆçš„èº«ä»½ï¼Œå¯¹å­¦ç”Ÿæäº¤çš„ä½œæ–‡è¿›è¡Œå…¨é¢ã€ç»†è‡´ã€æ·±å…¥çš„æ‰¹æ”¹ã€‚
åœ¨æ‰¹æ”¹è¿‡ç¨‹ä¸­ï¼Œè¯·ç‰¹åˆ«æ³¨æ„ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

1. å®¡é¢˜ç«‹æ„æ–¹é¢ï¼š
   - å­¦ç”Ÿæ˜¯å¦å‡†ç¡®ç†è§£äº†é¢˜ç›®çš„è¦æ±‚
   - æ–‡ç« çš„ä¸»é¢˜æ€æƒ³æ˜¯å¦é²œæ˜
   - ç«‹æ„æ˜¯å¦æ–°é¢–æ·±åˆ»
   - æ˜¯å¦å­˜åœ¨åé¢˜è·‘é¢˜çš„æƒ…å†µ
   ...ï¼ˆç»§ç»­å†—é•¿æè¿°ï¼‰

2. å†…å®¹ç»“æ„æ–¹é¢ï¼š
   ...ï¼ˆç»§ç»­å†—é•¿æè¿°ï¼‰
</code></pre>
<p><strong>ä¼˜åŒ–å</strong>ï¼ˆ680 tokensï¼ŒèŠ‚çœ76%ï¼‰ï¼š</p>
<pre><code>é«˜ä¸­è¯­æ–‡æ•™å¸ˆï¼Œ20å¹´ç»éªŒã€‚æ‰¹æ”¹ä½œæ–‡ã€‚

è¯„åˆ†æ ‡å‡†ï¼š
1. å®¡é¢˜ç«‹æ„30åˆ†ï¼šä¸»é¢˜ã€ç«‹æ„ã€åˆ‡é¢˜
2. å†…å®¹ç»“æ„25åˆ†ï¼šè®ºè¯ã€ç»“æ„
3. è¯­è¨€è¡¨è¾¾25åˆ†ï¼šæµç•…ã€ä¿®è¾
4. åˆ›æ–°20åˆ†ï¼šè§è§£ã€è¡¨è¾¾

è¾“å‡ºï¼š
- æ€»åˆ†åŠåˆ†é¡¹åˆ†æ•°
- æ¯é¡¹2-3å¥è¯„è¯­
- 3-5ä¸ªä¼˜ç‚¹ï¼ˆå…·ä½“åˆ°æ®µè½ï¼‰
- 3-5ä¸ªæ”¹è¿›å»ºè®®

ä½œæ–‡ï¼š
{essay_content}
</code></pre>
<h3>4.2 Promptå‹ç¼©æŠ€æœ¯</h3>
<h4>æŠ€å·§1ï¼šå»é™¤ä¿®é¥°è¯</h4>
<pre><code>ä¼˜åŒ–å‰: &quot;éå¸¸é‡è¦çš„æ³¨æ„äº‹é¡¹&quot;
ä¼˜åŒ–å: &quot;æ³¨æ„äº‹é¡¹&quot;
èŠ‚çœ: 5 tokens â†’ 2 tokens
</code></pre>
<h4>æŠ€å·§2ï¼šä½¿ç”¨ç¼©å†™å’Œç¬¦å·</h4>
<pre><code>ä¼˜åŒ–å‰: &quot;è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼šç¬¬ä¸€æ­¥ã€ç¬¬äºŒæ­¥ã€ç¬¬ä¸‰æ­¥&quot;
ä¼˜åŒ–å: &quot;æ­¥éª¤ï¼š1. 2. 3.&quot;
èŠ‚çœ: 18 tokens â†’ 8 tokens
</code></pre>
<h4>æŠ€å·§3ï¼šç§»é™¤é‡å¤å†…å®¹</h4>
<pre><code class="language-python">def compress_prompt(prompt):
    &quot;&quot;&quot;
    è‡ªåŠ¨å‹ç¼©æç¤ºè¯
    &quot;&quot;&quot;
    import re

    # å»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
    prompt = re.sub(r&#39;\s+&#39;, &#39; &#39;, prompt)

    # å»é™¤ä¿®é¥°è¯
    fillers = [&#39;éå¸¸&#39;, &#39;ç‰¹åˆ«&#39;, &#39;å°¤å…¶&#39;, &#39;è¯·&#39;, &#39;çš„è¯&#39;, &#39;ç­‰ç­‰&#39;]
    for filler in fillers:
        prompt = prompt.replace(filler, &#39;&#39;)

    # ç¼©å†™å¸¸è§è¯
    replacements = {
        &#39;ç¬¬ä¸€æ­¥&#39;: &#39;1.&#39;,
        &#39;ç¬¬äºŒæ­¥&#39;: &#39;2.&#39;,
        &#39;ç¬¬ä¸‰æ­¥&#39;: &#39;3.&#39;,
        &#39;è¯·æ³¨æ„&#39;: &#39;æ³¨æ„&#39;,
        &#39;éœ€è¦&#39;: &#39;éœ€&#39;,
        &#39;åº”è¯¥&#39;: &#39;åº”&#39;,
    }
    for old, new in replacements.items():
        prompt = prompt.replace(old, new)

    return prompt.strip()
</code></pre>
<p><strong>æ•ˆæœå¯¹æ¯”</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>æç¤ºè¯ç±»å‹</th>
<th>åŸé•¿åº¦</th>
<th>å‹ç¼©å</th>
<th>èŠ‚çœ</th>
<th>è´¨é‡æŸå¤±</th>
</tr>
</thead>
<tbody><tr>
<td>å®¢æœç³»ç»Ÿ</td>
<td>1,200</td>
<td>350</td>
<td>71%</td>
<td>&lt;2%</td>
</tr>
<tr>
<td>ä»£ç å®¡æŸ¥</td>
<td>850</td>
<td>280</td>
<td>67%</td>
<td>&lt;1%</td>
</tr>
<tr>
<td>ä½œæ–‡æ‰¹æ”¹</td>
<td>2,800</td>
<td>680</td>
<td>76%</td>
<td>&lt;3%</td>
</tr>
</tbody></table>
<p><strong>æœˆåº¦æˆæœ¬èŠ‚çœ</strong>ï¼š<code>$1,200 â†’ $500</code>ï¼ˆ-58%ï¼‰</p>
<h2>äº”ã€ä¼˜åŒ–ç­–ç•¥ä¸‰ï¼šç¼“å­˜ç³»ç»Ÿ</h2>
<h3>5.1 å¤šçº§ç¼“å­˜æ¶æ„</h3>
<pre><code>è¯·æ±‚ â†’ L1æœ¬åœ°ç¼“å­˜(Caffeine) â†’ L2 Redis â†’ L3è¯­ä¹‰ç¼“å­˜ â†’ LLM API
       â†“ å‘½ä¸­98%            â†“ å‘½ä¸­1.8%  â†“ å‘½ä¸­0.1%   â†“ 0.1%
</code></pre>
<h3>5.2 å®ç°ä»£ç </h3>
<pre><code class="language-python">from functools import lru_cache
import redis
import hashlib
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class LLMCache:
    def __init__(self):
        self.redis_client = redis.Redis(host=&#39;localhost&#39;, port=6379)
        self.embedding_cache = {}  # è¯­ä¹‰ç¼“å­˜

    @lru_cache(maxsize=1000)  # L1: æœ¬åœ°ç¼“å­˜
    def get_or_call(self, prompt, model=&quot;gpt-3.5-turbo&quot;):
        &quot;&quot;&quot;
        ä¸‰çº§ç¼“å­˜æŸ¥è¯¢
        &quot;&quot;&quot;
        # ç”Ÿæˆç¼“å­˜key
        cache_key = hashlib.md5(f&quot;{model}:{prompt}&quot;.encode()).hexdigest()

        # L2: Redisç²¾ç¡®åŒ¹é…
        cached = self.redis_client.get(cache_key)
        if cached:
            print(&quot;âœ… Redisç¼“å­˜å‘½ä¸­&quot;)
            return cached.decode(&#39;utf-8&#39;)

        # L3: è¯­ä¹‰ç›¸ä¼¼ç¼“å­˜
        semantic_result = self.semantic_search(prompt)
        if semantic_result:
            print(&quot;âœ… è¯­ä¹‰ç¼“å­˜å‘½ä¸­&quot;)
            return semantic_result

        # è°ƒç”¨LLM API
        print(&quot;ğŸ”´ ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨API&quot;)
        result = self.call_llm(prompt, model)

        # å†™å…¥ç¼“å­˜
        self.redis_client.setex(cache_key, 3600, result)  # 1å°æ—¶è¿‡æœŸ
        self.add_to_semantic_cache(prompt, result)

        return result

    def semantic_search(self, query, threshold=0.95):
        &quot;&quot;&quot;
        è¯­ä¹‰ç›¸ä¼¼æœç´¢ï¼ˆå¤„ç†paraphraseï¼‰
        &quot;&quot;&quot;
        if not self.embedding_cache:
            return None

        # è®¡ç®—queryçš„embedding
        query_emb = self.get_embedding(query)

        # ä¸ç¼“å­˜ä¸­çš„embeddingè®¡ç®—ç›¸ä¼¼åº¦
        max_similarity = 0
        best_match = None

        for cached_query, (cached_emb, cached_result) in self.embedding_cache.items():
            similarity = cosine_similarity([query_emb], [cached_emb])[0][0]

            if similarity &gt; max_similarity:
                max_similarity = similarity
                best_match = cached_result

        # ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼ï¼Œè¿”å›ç¼“å­˜ç»“æœ
        if max_similarity &gt;= threshold:
            return best_match

        return None

    def add_to_semantic_cache(self, query, result):
        &quot;&quot;&quot;
        æ·»åŠ åˆ°è¯­ä¹‰ç¼“å­˜
        &quot;&quot;&quot;
        emb = self.get_embedding(query)
        self.embedding_cache[query] = (emb, result)

        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.embedding_cache) &gt; 5000:
            # åˆ é™¤æœ€æ—©çš„1000æ¡
            for i, key in enumerate(list(self.embedding_cache.keys())[:1000]):
                del self.embedding_cache[key]

    def get_embedding(self, text):
        &quot;&quot;&quot;
        è·å–æ–‡æœ¬embeddingï¼ˆç®€åŒ–ï¼Œå®é™…åº”è°ƒç”¨embedding APIæˆ–æœ¬åœ°æ¨¡å‹ï¼‰
        &quot;&quot;&quot;
        from openai import OpenAI
        client = OpenAI()

        response = client.embeddings.create(
            model=&quot;text-embedding-3-small&quot;,
            input=text
        )
        return response.data[0].embedding

    def call_llm(self, prompt, model):
        &quot;&quot;&quot;
        å®é™…è°ƒç”¨LLM API
        &quot;&quot;&quot;
        from openai import OpenAI
        client = OpenAI()

        response = client.chat.completions.create(
            model=model,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}]
        )
        return response.choices[0].message.content
</code></pre>
<h3>5.3 ç¼“å­˜æ•ˆæœåˆ†æ</h3>
<p><strong>çœŸå®æ•°æ®</strong>ï¼ˆæ•™è‚²åœºæ™¯ï¼‰ï¼š</p>
<pre><code>æ—¥è¯·æ±‚é‡: 15,000æ¬¡

L1æœ¬åœ°ç¼“å­˜å‘½ä¸­: 14,700æ¬¡ (98%)
L2 Rediså‘½ä¸­: 270æ¬¡ (1.8%)
L3è¯­ä¹‰ç¼“å­˜å‘½ä¸­: 15æ¬¡ (0.1%)
å®é™…APIè°ƒç”¨: 15æ¬¡ (0.1%)

æˆæœ¬å¯¹æ¯”ï¼š
æ— ç¼“å­˜: 15,000 Ã— $0.011 = $165/å¤©
æœ‰ç¼“å­˜: 15 Ã— $0.011 = $0.165/å¤©

æœˆåº¦èŠ‚çœ: $4,950 - $4.95 = $4,945ï¼ˆ99.9%ï¼‰
</code></pre>
<p><strong>æ³¨æ„äº‹é¡¹</strong>ï¼š</p>
<ol>
<li><strong>ç¼“å­˜è¿‡æœŸç­–ç•¥</strong></li>
</ol>
<pre><code class="language-python"># ä¸åŒç±»å‹å†…å®¹è®¾ç½®ä¸åŒè¿‡æœŸæ—¶é—´
cache_ttl = {
    &#39;static_content&#39;: 86400,  # é™æ€å†…å®¹24å°æ—¶
    &#39;user_query&#39;: 3600,       # ç”¨æˆ·é—®ç­”1å°æ—¶
    &#39;realtime_data&#39;: 300      # å®æ—¶æ•°æ®5åˆ†é’Ÿ
}
</code></pre>
<ol start="2">
<li><strong>ç¼“å­˜æ›´æ–°æœºåˆ¶</strong></li>
</ol>
<pre><code class="language-python"># ç›‘å¬å†…å®¹æ›´æ–°ï¼Œä¸»åŠ¨å¤±æ•ˆç¼“å­˜
@app.route(&#39;/admin/update_content&#39;, methods=[&#39;POST&#39;])
def update_content():
    content_id = request.json[&#39;id&#39;]

    # æ›´æ–°æ•°æ®åº“
    db.update(content_id)

    # å¤±æ•ˆç›¸å…³ç¼“å­˜
    cache_keys = redis_client.keys(f&quot;*{content_id}*&quot;)
    for key in cache_keys:
        redis_client.delete(key)

    return {&quot;status&quot;: &quot;ok&quot;}
</code></pre>
<h2>å…­ã€ä¼˜åŒ–ç­–ç•¥å››ï¼šæœ¬åœ°æ¨¡å‹éƒ¨ç½²</h2>
<h3>6.1 å¼€æºæ¨¡å‹é€‰å‹</h3>
<table>
<thead>
<tr>
<th>æ¨¡å‹</th>
<th>å‚æ•°é‡</th>
<th>æ€§èƒ½</th>
<th>æˆæœ¬</th>
<th>é€‚ç”¨åœºæ™¯</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Llama 3.1 70B</strong></td>
<td>70B</td>
<td>GPT-4ç›¸å½“</td>
<td>GPUæœåŠ¡å™¨$500/æœˆ</td>
<td>é€šç”¨ä»»åŠ¡</td>
</tr>
<tr>
<td><strong>Qwen2.5 72B</strong></td>
<td>72B</td>
<td>GPT-4-Turboç›¸å½“</td>
<td>GPUæœåŠ¡å™¨$500/æœˆ</td>
<td>ä¸­æ–‡ä»»åŠ¡</td>
</tr>
<tr>
<td><strong>Mistral Large</strong></td>
<td>123B</td>
<td>æ¥è¿‘GPT-4</td>
<td>GPUæœåŠ¡å™¨$800/æœˆ</td>
<td>æ¬§æ´²è¯­è¨€</td>
</tr>
<tr>
<td><strong>DeepSeek V2</strong></td>
<td>236B</td>
<td>GPT-4+</td>
<td>å¤šå¡$1500/æœˆ</td>
<td>ä»£ç ä»»åŠ¡</td>
</tr>
</tbody></table>
<h3>6.2 æ··åˆéƒ¨ç½²æ¶æ„</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           API Gateway               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     æ™ºèƒ½è·¯ç”±å±‚            â”‚
    â”‚  (åˆ†æä»»åŠ¡ç±»å‹å’Œå¤æ‚åº¦)   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚            â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ æœ¬åœ°æ¨¡å‹  â”‚  â”‚ OpenAI API â”‚
  â”‚ Llama3.1  â”‚  â”‚  (å¤‡ç”¨)     â”‚
  â”‚ (90%æµé‡) â”‚  â”‚  (10%æµé‡) â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>6.3 vLLMéƒ¨ç½²æŒ‡å—</h3>
<p><strong>å®‰è£…vLLM</strong>ï¼š</p>
<pre><code class="language-bash">pip install vllm
</code></pre>
<p><strong>å¯åŠ¨æ¨ç†æœåŠ¡</strong>ï¼š</p>
<pre><code class="language-python">from vllm import LLM, SamplingParams

# åŠ è½½æ¨¡å‹
llm = LLM(
    model=&quot;meta-llama/Llama-3.1-70B-Instruct&quot;,
    tensor_parallel_size=2,  # ä½¿ç”¨2å¼ GPU
    max_model_len=8192,      # ä¸Šä¸‹æ–‡é•¿åº¦
    gpu_memory_utilization=0.9
)

# æ¨ç†é…ç½®
sampling_params = SamplingParams(
    temperature=0.7,
    top_p=0.95,
    max_tokens=1024
)

# æ‰¹é‡æ¨ç†ï¼ˆæå‡ååé‡ï¼‰
prompts = [
    &quot;æ‰¹æ”¹è¿™ç¯‡ä½œæ–‡ï¼š...&quot;,
    &quot;ç¿»è¯‘è¿™æ®µæ–‡å­—ï¼š...&quot;,
    # ... æ›´å¤šè¯·æ±‚
]

outputs = llm.generate(prompts, sampling_params)

for output in outputs:
    print(output.outputs[0].text)
</code></pre>
<p><strong>APIæœåŠ¡åŒ–</strong>ï¼ˆå…¼å®¹OpenAIæ¥å£ï¼‰ï¼š</p>
<pre><code class="language-bash">python -m vllm.entrypoints.openai.api_server \
    --model meta-llama/Llama-3.1-70B-Instruct \
    --tensor-parallel-size 2 \
    --port 8000
</code></pre>
<p><strong>å®¢æˆ·ç«¯è°ƒç”¨</strong>ï¼š</p>
<pre><code class="language-python">from openai import OpenAI

# æŒ‡å‘æœ¬åœ°vLLMæœåŠ¡
client = OpenAI(
    base_url=&quot;http://localhost:8000/v1&quot;,
    api_key=&quot;dummy&quot;  # vLLMä¸éœ€è¦çœŸå®API key
)

response = client.chat.completions.create(
    model=&quot;meta-llama/Llama-3.1-70B-Instruct&quot;,
    messages=[
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;æ‰¹æ”¹è¿™ç¯‡ä½œæ–‡ï¼š...&quot;}
    ]
)
</code></pre>
<h3>6.4 æˆæœ¬å¯¹æ¯”åˆ†æ</h3>
<p><strong>æ–¹æ¡ˆAï¼šçº¯OpenAI API</strong></p>
<pre><code>æœˆè¯·æ±‚é‡ï¼š450,000æ¬¡ï¼ˆ15,000/å¤© Ã— 30å¤©ï¼‰
å¹³å‡æˆæœ¬ï¼š$0.011/æ¬¡ï¼ˆæ··åˆGPT-3.5å’ŒGPT-4ï¼‰

æœˆæˆæœ¬ï¼š$4,950
</code></pre>
<p><strong>æ–¹æ¡ˆBï¼šæœ¬åœ°Llama 3.1 70B</strong></p>
<pre><code>GPUæœåŠ¡å™¨ï¼š2Ã—A100ï¼ˆ80GBï¼‰
ç§Ÿèµæˆæœ¬ï¼š$500/æœˆï¼ˆäº‘æœåŠ¡å•†ï¼‰

æœˆæˆæœ¬ï¼š$500
èŠ‚çœï¼š$4,450ï¼ˆ90%ï¼‰
</code></pre>
<p><strong>æ–¹æ¡ˆCï¼šæ··åˆéƒ¨ç½²ï¼ˆæ¨èï¼‰</strong></p>
<pre><code>æœ¬åœ°æ¨¡å‹å¤„ç†ï¼š90%ï¼ˆ405,000æ¬¡ï¼‰
OpenAI APIå¤„ç†ï¼š10%ï¼ˆ45,000æ¬¡ï¼Œå¤æ‚ä»»åŠ¡ï¼‰

æœ¬åœ°æˆæœ¬ï¼š$500/æœˆ
APIæˆæœ¬ï¼š45,000 Ã— $0.022 = $990/æœˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ€»æˆæœ¬ï¼š$1,490/æœˆ
èŠ‚çœï¼š$3,460ï¼ˆ70%ï¼‰

ä¼˜åŠ¿ï¼š
âœ… æˆæœ¬é™ä½70%
âœ… ä¿ç•™OpenAIä½œä¸ºbackupï¼Œè´¨é‡æœ‰ä¿éšœ
âœ… å¤æ‚ä»»åŠ¡ä»ç”¨GPT-4ï¼Œå‡†ç¡®ç‡ä¸ä¸‹é™
</code></pre>
<h2>ä¸ƒã€ä¼˜åŒ–ç­–ç•¥äº”ï¼šæµå¼è¾“å‡º</h2>
<h3>7.1 é—®é¢˜åˆ†æ</h3>
<p><strong>éæµå¼</strong>ï¼ˆç”¨æˆ·ä½“éªŒå·®ï¼‰ï¼š</p>
<pre><code>ç”¨æˆ·æäº¤é—®é¢˜ â†’ ç­‰å¾…15ç§’ â†’ ä¸€æ¬¡æ€§æ˜¾ç¤ºå®Œæ•´ç­”æ¡ˆ

ç¼ºç‚¹ï¼š
- ç”¨æˆ·ä¸çŸ¥é“ç³»ç»Ÿæ˜¯å¦åœ¨å·¥ä½œ
- é•¿æ—¶é—´ç©ºç™½ç­‰å¾…ï¼Œè·³å‡ºç‡é«˜
- æœåŠ¡å™¨éœ€è¦ç­‰å¾…å®Œæ•´å“åº”ï¼Œå†…å­˜å ç”¨å¤§
</code></pre>
<p><strong>æµå¼</strong>ï¼ˆç”¨æˆ·ä½“éªŒå¥½ï¼‰ï¼š</p>
<pre><code>ç”¨æˆ·æäº¤é—®é¢˜ â†’ 1ç§’åå¼€å§‹é€å­—æ˜¾ç¤º â†’ æŒç»­15ç§’ â†’ å®Œæˆ

ä¼˜ç‚¹ï¼š
âœ… å³æ—¶åé¦ˆï¼Œç”¨æˆ·ä½“éªŒå¥½
âœ… é™ä½æ„ŸçŸ¥ç­‰å¾…æ—¶é—´
âœ… æœåŠ¡å™¨å¯è¾¹ç”Ÿæˆè¾¹ï¿½ï¿½ï¿½å›ï¼Œå‡å°‘å†…å­˜
</code></pre>
<h3>7.2 å®ç°æµå¼è¾“å‡º</h3>
<pre><code class="language-python">from openai import OpenAI

client = OpenAI()

def stream_chat(messages):
    &quot;&quot;&quot;
    æµå¼è°ƒç”¨GPT
    &quot;&quot;&quot;
    stream = client.chat.completions.create(
        model=&quot;gpt-4-turbo&quot;,
        messages=messages,
        stream=True  # å¯ç”¨æµå¼
    )

    full_response = &quot;&quot;

    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            content = chunk.choices[0].delta.content
            full_response += content
            print(content, end=&#39;&#39;, flush=True)  # å®æ—¶è¾“å‡º

    return full_response

# Flask APIç¤ºä¾‹
from flask import Flask, Response, stream_with_context

app = Flask(__name__)

@app.route(&#39;/chat/stream&#39;, methods=[&#39;POST&#39;])
def chat_stream():
    messages = request.json[&#39;messages&#39;]

    def generate():
        stream = client.chat.completions.create(
            model=&quot;gpt-4-turbo&quot;,
            messages=messages,
            stream=True
        )

        for chunk in stream:
            if chunk.choices[0].delta.content:
                # SSEæ ¼å¼
                yield f&quot;data: {chunk.choices[0].delta.content}\n\n&quot;

    return Response(stream_with_context(generate()),
                    mimetype=&#39;text/event-stream&#39;)

# å‰ç«¯æ¥æ”¶ï¼ˆJavaScriptï¼‰
const eventSource = new EventSource(&#39;/chat/stream&#39;);

eventSource.onmessage = (event) =&gt; {
    document.getElementById(&#39;response&#39;).innerText += event.data;
};
</code></pre>
<h3>7.3 æˆæœ¬ä¼˜åŠ¿</h3>
<p><strong>ç”¨æˆ·ä½“éªŒæå‡</strong> = <strong>ç•™å­˜ç‡æå‡</strong> = <strong>é•¿æœŸæˆæœ¬é™ä½</strong></p>
<pre><code>æ¡ˆä¾‹æ•°æ®ï¼š
éæµå¼ç‰ˆæœ¬ï¼š
- å¹³å‡ç­‰å¾…æ—¶é—´ï¼š12ç§’
- è·³å‡ºç‡ï¼š35%ï¼ˆç”¨æˆ·æ”¾å¼ƒæé—®ï¼‰
- æœ‰æ•ˆè¯·æ±‚ï¼š65%

æµå¼ç‰ˆæœ¬ï¼š
- é¦–å­—å»¶è¿Ÿï¼š0.8ç§’
- è·³å‡ºç‡ï¼š8%
- æœ‰æ•ˆè¯·æ±‚ï¼š92%

æˆæœ¬å½±å“ï¼š
æµªè´¹çš„APIè°ƒç”¨ï¼ˆè¢«æ”¾å¼ƒçš„è¯·æ±‚ï¼‰ï¼š
éæµå¼ï¼š35% Ã— 15,000 = 5,250æ¬¡/å¤© Ã— $0.011 = $57.75/å¤©
æµå¼ï¼š8% Ã— 15,000 = 1,200æ¬¡/å¤© Ã— $0.011 = $13.2/å¤©

æœˆèŠ‚çœï¼š($57.75 - $13.2) Ã— 30 = $1,336
</code></pre>
<h2>å…«ã€ä¼˜åŒ–ç­–ç•¥å…­ï¼šå¼‚æ­¥å¤„ç†</h2>
<h3>8.1 æ‰¹é‡å¤„ç†ï¼ˆBatchingï¼‰</h3>
<p><strong>é—®é¢˜</strong>ï¼šå®æ—¶è°ƒç”¨LLMï¼Œæ¯æ¬¡è¯·æ±‚éƒ½è¦ç­‰å¾…</p>
<pre><code class="language-python"># âŒ é€ä¸ªå¤„ç†ï¼ˆä½æ•ˆï¼‰
for user_essay in essays:
    result = grade_essay(user_essay)  # æ¯æ¬¡ç­‰å¾…2-5ç§’
    save_result(result)

# æ€»è€—æ—¶ï¼š1000ç¯‡ Ã— 3ç§’ = 50åˆ†é’Ÿ
</code></pre>
<p><strong>ä¼˜åŒ–</strong>ï¼šæ‰¹é‡å¤„ç†</p>
<pre><code class="language-python"># âœ… æ‰¹é‡å¤„ç†ï¼ˆé«˜æ•ˆï¼‰
from vllm import LLM

llm = LLM(&quot;meta-llama/Llama-3.1-70B-Instruct&quot;)

# ä¸€æ¬¡æ€§ç”Ÿæˆ1000ä¸ªç»“æœ
prompts = [format_prompt(essay) for essay in essays]
results = llm.generate(prompts)  # vLLMè‡ªåŠ¨æ‰¹å¤„ç†

# æ€»è€—æ—¶ï¼šçº¦8åˆ†é’Ÿï¼ˆæå‡6å€ï¼‰
</code></pre>
<p><strong>æˆæœ¬èŠ‚çœ</strong>ï¼š</p>
<ul>
<li>æœåŠ¡å™¨åˆ©ç”¨ç‡æå‡ï¼š30% â†’ 85%</li>
<li>GPUå°æ—¶æˆæœ¬ï¼š$2.5/h â†’ $0.8/hï¼ˆå‡å°‘ç©ºé—²æ—¶é—´ï¼‰</li>
</ul>
<h3>8.2 æ¶ˆæ¯é˜Ÿåˆ—å¼‚æ­¥å¤„ç†</h3>
<pre><code class="language-python"># ä½¿ç”¨Celeryå¼‚æ­¥ä»»åŠ¡
from celery import Celery

app = Celery(&#39;tasks&#39;, broker=&#39;redis://localhost:6379/0&#39;)

@app.task
def grade_essay_async(essay_id):
    &quot;&quot;&quot;
    å¼‚æ­¥æ‰¹æ”¹ä½œæ–‡
    &quot;&quot;&quot;
    essay = db.get_essay(essay_id)

    # è°ƒç”¨LLM
    result = llm.generate(format_prompt(essay))

    # ä¿å­˜ç»“æœ
    db.save_result(essay_id, result)

    # é€šçŸ¥ç”¨æˆ·ï¼ˆWebSocket/é‚®ä»¶ï¼‰
    notify_user(essay.user_id, &quot;æ‰¹æ”¹å®Œæˆ&quot;)

# APIæ¥å£ï¼ˆç«‹å³è¿”å›ï¼‰
@app.route(&#39;/submit_essay&#39;, methods=[&#39;POST&#39;])
def submit_essay():
    essay_id = save_essay(request.json)

    # æäº¤å¼‚æ­¥ä»»åŠ¡
    grade_essay_async.delay(essay_id)

    return {&quot;status&quot;: &quot;submitted&quot;, &quot;essay_id&quot;: essay_id}
</code></pre>
<p><strong>ä¼˜åŠ¿</strong>ï¼š</p>
<ol>
<li><strong>å‰Šå³°å¡«è°·</strong>ï¼šé«˜å³°æœŸä»»åŠ¡æ’é˜Ÿï¼Œä½è°·æœŸå¤„ç†</li>
<li><strong>èµ„æºå¤ç”¨</strong>ï¼šå¤šä¸ªä»»åŠ¡å…±äº«GPUï¼Œæå‡åˆ©ç”¨ç‡</li>
<li><strong>æˆæœ¬ä¼˜åŒ–</strong>ï¼šæŒ‰éœ€æ‰©å®¹ï¼Œé¿å…è¿‡åº¦é…ç½®</li>
</ol>
<h2>ä¹ã€ä¼˜åŒ–ç­–ç•¥ä¸ƒï¼šç›‘æ§ä¸åˆ†æ</h2>
<h3>9.1 æˆæœ¬ç›‘æ§Dashboard</h3>
<pre><code class="language-python">import prometheus_client as prom

# å®šä¹‰æŒ‡æ ‡
api_cost_counter = prom.Counter(
    &#39;llm_api_cost_dollars&#39;,
    &#39;LLM APIè°ƒç”¨æˆæœ¬ï¼ˆç¾å…ƒï¼‰&#39;,
    [&#39;model&#39;, &#39;task_type&#39;]
)

token_usage_histogram = prom.Histogram(
    &#39;llm_token_usage&#39;,
    &#39;Tokenä½¿ç”¨é‡&#39;,
    [&#39;model&#39;, &#39;direction&#39;],  # input/output
    buckets=[100, 500, 1000, 2000, 5000, 10000]
)

# è®°å½•æ¯æ¬¡è°ƒç”¨
def track_llm_call(model, task_type, input_tokens, output_tokens):
    # è®¡ç®—æˆæœ¬
    cost = calculate_cost(input_tokens, output_tokens, model)

    # è®°å½•æŒ‡æ ‡
    api_cost_counter.labels(model=model, task_type=task_type).inc(cost)
    token_usage_histogram.labels(model=model, direction=&#39;input&#39;).observe(input_tokens)
    token_usage_histogram.labels(model=model, direction=&#39;output&#39;).observe(output_tokens)

# GrafanaæŸ¥è¯¢è¯­å¥
# æœˆåº¦æˆæœ¬: sum(increase(llm_api_cost_dollars[30d]))
# æˆæœ¬åˆ†å¸ƒ: sum by (task_type) (llm_api_cost_dollars)
</code></pre>
<h3>9.2 å¼‚å¸¸æ£€æµ‹</h3>
<pre><code class="language-python">def detect_cost_anomaly():
    &quot;&quot;&quot;
    æ£€æµ‹æˆæœ¬å¼‚å¸¸ï¼ˆå¦‚çªç„¶æš´æ¶¨ï¼‰
    &quot;&quot;&quot;
    current_hour_cost = get_hourly_cost()
    avg_hourly_cost = get_avg_hourly_cost(days=7)

    # è¶…è¿‡å¹³å‡å€¼3å€ï¼Œè§¦å‘å‘Šè­¦
    if current_hour_cost &gt; avg_hourly_cost * 3:
        alert(f&quot;æˆæœ¬å¼‚å¸¸ï¼å½“å‰: ${current_hour_cost}, å¹³å‡: ${avg_hourly_cost}&quot;)

        # è‡ªåŠ¨é™çº§ï¼šåˆ‡æ¢åˆ°ä¾¿å®œæ¨¡å‹
        enable_cost_saving_mode()
</code></pre>
<h3>9.3 æˆæœ¬å½’å› åˆ†æ</h3>
<pre><code class="language-python"># åˆ†æï¼šå“ªäº›ç”¨æˆ·/åŠŸèƒ½æ¶ˆè€—æœ€å¤šï¼Ÿ
def analyze_cost_by_user():
    query = &quot;&quot;&quot;
    SELECT
        user_id,
        SUM(cost) as total_cost,
        COUNT(*) as request_count,
        AVG(cost) as avg_cost
    FROM llm_usage_log
    WHERE created_at &gt;= NOW() - INTERVAL &#39;30 days&#39;
    GROUP BY user_id
    ORDER BY total_cost DESC
    LIMIT 100
    &quot;&quot;&quot;

    top_users = db.execute(query)

    # å‘ç°ï¼š10%çš„é‡åº¦ç”¨æˆ·æ¶ˆè€—äº†70%çš„æˆæœ¬
    # ç­–ç•¥ï¼šä¸ºé‡åº¦ç”¨æˆ·æä¾›åŒ…æœˆå¥—é¤ï¼Œé™ä½è¾¹é™…æˆæœ¬
</code></pre>
<h2>åã€æˆæœ¬ä¼˜åŒ–å†³ç­–æ ‘</h2>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ¯æœˆæˆæœ¬ &gt; $1000? â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
    YESâ”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. å®æ–½ç¼“å­˜ç³»ç»Ÿ     â”‚ â†’ é¢„è®¡èŠ‚çœ50-70%
â”‚ 2. Promptå‹ç¼©       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ¯æœˆæˆæœ¬ &gt; $500?  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
    YESâ”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. æ™ºèƒ½æ¨¡å‹è·¯ç”±     â”‚ â†’ é¢„è®¡èŠ‚çœ30-50%
â”‚ 4. æœ¬åœ°æ¨¡å‹éƒ¨ç½²     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ¯æœˆæˆæœ¬ &gt; $200?  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
    YESâ”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. æ‰¹é‡å¤„ç†ä¼˜åŒ–     â”‚ â†’ é¢„è®¡èŠ‚çœ10-20%
â”‚ 6. å¼‚æ­¥é˜Ÿåˆ—ç®¡ç†     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2>åä¸€ã€å®Œæ•´ä¼˜åŒ–æ¸…å•</h2>
<h3>ç«‹å³å¯åšï¼ˆ1å¤©å†…ï¼‰</h3>
<ul>
<li><input disabled="" type="checkbox"> å¯ç”¨GPT-3.5æ›¿ä»£80%çš„GPT-4è°ƒç”¨</li>
<li><input disabled="" type="checkbox"> å‹ç¼©System Promptï¼ˆå»é™¤å†—ä½™è¯æ±‡ï¼‰</li>
<li><input disabled="" type="checkbox"> é…ç½®Redisç¼“å­˜ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰</li>
<li><input disabled="" type="checkbox"> æ·»åŠ æˆæœ¬ç›‘æ§ï¼ˆPrometheusï¼‰</li>
</ul>
<h3>çŸ­æœŸä¼˜åŒ–ï¼ˆ1å‘¨å†…ï¼‰</h3>
<ul>
<li><input disabled="" type="checkbox"> å®ç°æ™ºèƒ½æ¨¡å‹è·¯ç”±</li>
<li><input disabled="" type="checkbox"> éƒ¨ç½²è¯­ä¹‰ç¼“å­˜</li>
<li><input disabled="" type="checkbox"> ä¼˜åŒ–æ‰¹å¤„ç†é€»è¾‘</li>
<li><input disabled="" type="checkbox"> è®¾ç½®æˆæœ¬å‘Šè­¦</li>
</ul>
<h3>ä¸­æœŸè§„åˆ’ï¼ˆ1ä¸ªæœˆï¼‰</h3>
<ul>
<li><input disabled="" type="checkbox"> æœ¬åœ°æ¨¡å‹POCæµ‹è¯•</li>
<li><input disabled="" type="checkbox"> æ··åˆéƒ¨ç½²æ¶æ„</li>
<li><input disabled="" type="checkbox"> å®Œå–„ç›‘æ§Dashboard</li>
<li><input disabled="" type="checkbox"> æˆæœ¬å½’å› åˆ†æ</li>
</ul>
<h3>é•¿æœŸæŠ•èµ„ï¼ˆ3ä¸ªæœˆï¼‰</h3>
<ul>
<li><input disabled="" type="checkbox"> è‡ªå»ºGPUé›†ç¾¤</li>
<li><input disabled="" type="checkbox"> Fine-tuneå®šåˆ¶æ¨¡å‹</li>
<li><input disabled="" type="checkbox"> æè‡´æ€§èƒ½ä¼˜åŒ–</li>
</ul>
<h2>åäºŒã€æ€»ç»“</h2>
<h3>æ ¸å¿ƒè¦ç‚¹</h3>
<ol>
<li><strong>ä¸æ˜¯æ‰€æœ‰ä»»åŠ¡éƒ½éœ€è¦GPT-4</strong>ï¼š70%çš„ç®€å•ä»»åŠ¡ç”¨GPT-3.5å³å¯</li>
<li><strong>ç¼“å­˜æ˜¯æœ€é«˜æ•ˆçš„ä¼˜åŒ–</strong>ï¼š99%çš„å‘½ä¸­ç‡ = 99%çš„æˆæœ¬èŠ‚çœ</li>
<li><strong>æœ¬åœ°æ¨¡å‹æ˜¯ç»ˆææ–¹æ¡ˆ</strong>ï¼šé•¿æœŸçœ‹ï¼Œè‡ªå»ºGPUæˆæœ¬æ›´ä½</li>
<li><strong>æŒç»­ç›‘æ§å’Œä¼˜åŒ–</strong>ï¼šæˆæœ¬ä¼˜åŒ–æ˜¯æŒç»­è¿‡ç¨‹ï¼Œä¸æ˜¯ä¸€åŠ³æ°¸é€¸</li>
</ol>
<h3>é¢„æœŸæ•ˆæœ</h3>
<table>
<thead>
<tr>
<th>ä¼˜åŒ–é˜¶æ®µ</th>
<th>æœˆæˆæœ¬</th>
<th>èŠ‚çœæ¯”ä¾‹</th>
<th>å®æ–½éš¾åº¦</th>
</tr>
</thead>
<tbody><tr>
<td>åˆå§‹çŠ¶æ€</td>
<td>$5,150</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>å¿«é€Ÿä¼˜åŒ–</td>
<td>$1,500</td>
<td>71%</td>
<td>â­</td>
</tr>
<tr>
<td>æ·±åº¦ä¼˜åŒ–</td>
<td>$800</td>
<td>84%</td>
<td>â­â­â­</td>
</tr>
<tr>
<td>æè‡´ä¼˜åŒ–</td>
<td>$500</td>
<td>90%</td>
<td>â­â­â­â­â­</td>
</tr>
</tbody></table>
<hr>
<h2>å…³äºæˆ‘ä»¬</h2>
<p>æ™ºç†ç§‘æŠ€åœ¨AIåº”ç”¨æˆæœ¬ä¼˜åŒ–æ–¹é¢æœ‰ä¸°å¯Œç»éªŒï¼Œå·²å¸®åŠ©å¤šå®¶ä¼ä¸šé™ä½70-90%çš„AIæˆæœ¬ã€‚</p>
<p><strong>æœåŠ¡å†…å®¹</strong>ï¼š</p>
<ul>
<li>AIæˆæœ¬è¯Šæ–­ä¸ä¼˜åŒ–æ–¹æ¡ˆ</li>
<li>æœ¬åœ°æ¨¡å‹éƒ¨ç½²ä¸è°ƒä¼˜</li>
<li>æ··åˆäº‘æ¶æ„è®¾è®¡</li>
<li>é•¿æœŸæŠ€æœ¯é¡¾é—®</li>
</ul>
<p><strong>è”ç³»æˆ‘ä»¬</strong>ï¼š</p>
<ul>
<li>ğŸ“§ é‚®ç®±: <a href="mailto:wuning@wanli.ai">wuning@wanli.ai</a></li>
<li>ğŸŒ å®˜ç½‘: <a href="https://zhili.wanli.ai">https://zhili.wanli.ai</a></li>
<li>ğŸ“ æŠ€æœ¯åšå®¢: <a href="https://zhili.wanli.ai/blog/">https://zhili.wanli.ai/blog/</a></li>
</ul>
<p>è®©AIåº”ç”¨æ›´ç»æµã€æ›´é«˜æ•ˆï¼</p>

<!-- ç›¸å…³æ¨è -->
<div class="mt-16 border-t border-gray-200 pt-12">
    <h2 class="text-2xl font-bold text-gray-900 mb-6 flex items-center">
        <span class="w-1 h-6 bg-blue-600 mr-3"></span>
        ç›¸å…³æ¨è
    </h2>
    <div class="grid md:grid-cols-2 gap-6">
        <a href="prompt-engineering-complete-guide.html" class="block p-4 bg-gray-50 rounded-lg hover:bg-gray-100 transition">
            <span class="inline-block px-2 py-1 text-xs font-medium rounded bg-blue-100 text-blue-800 mb-2">AIåº”ç”¨å¼€å‘</span>
            <h4 class="font-semibold text-gray-900 mb-2">æç¤ºè¯å·¥ç¨‹å®Œå…¨æŒ‡å—ï¼šä»å…¥é—¨åˆ°ç²¾é€š</h4>
            <p class="text-sm text-gray-600">ç³»ç»Ÿè®²è§£æç¤ºè¯å·¥ç¨‹çš„æ ¸å¿ƒåŸç†ã€è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µ</p>
        </a>
        <a href="rag-enterprise-knowledge-base.html" class="block p-4 bg-gray-50 rounded-lg hover:bg-gray-100 transition">
            <span class="inline-block px-2 py-1 text-xs font-medium rounded bg-blue-100 text-blue-800 mb-2">AIåº”ç”¨å¼€å‘</span>
            <h4 class="font-semibold text-gray-900 mb-2">RAGæŠ€æœ¯åœ¨ä¼ä¸šçŸ¥è¯†åº“ä¸­çš„åº”ç”¨å®è·µ</h4>
            <p class="text-sm text-gray-600">æ·±å…¥è§£æRAGæŠ€æœ¯å¦‚ä½•è§£å†³ä¼ä¸šçŸ¥è¯†åº“åº”ç”¨ç—›ç‚¹</p>
        </a>
    </div>
</div>

            </article>

            <!-- è”ç³»å¡ç‰‡ -->
            <div class="contact-card mt-12">
                <h3 class="text-xl font-bold text-white mb-3">ğŸ’¡ éœ€è¦æŠ€æœ¯æ”¯æŒï¼Ÿ</h3>
                <p class="text-white/90 mb-4">æ™ºç†ç§‘æŠ€ä¸“æ³¨äºä¼ä¸šçº§AIåº”ç”¨å¼€å‘ï¼Œæˆ‘ä»¬æä¾›ä»éœ€æ±‚åˆ†æã€æŠ€æœ¯é€‰å‹åˆ°å¼€å‘ä¸Šçº¿çš„å…¨æµç¨‹æœåŠ¡ã€‚</p>
                <div class="flex flex-col sm:flex-row gap-4">
                    <a href="mailto:wuning@wanli.ai" class="inline-flex items-center text-white hover:text-white/90">
                        <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 8l7.89 5.26a2 2 0 002.22 0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z"></path>
                        </svg>
                        wuning@wanli.ai
                    </a>
                    <a href="https://zhili.wanli.ai" class="inline-flex items-center text-white hover:text-white/90">
                        <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 12a9 9 0 01-9 9m9-9a9 9 0 00-9-9m9 9H3m9 9a9 9 0 01-9-9m9 9c1.657 0 3-4.03 3-9s-1.343-9-3-9m0 18c-1.657 0-3-4.03-3-9s1.343-9 3-9m-9 9a9 9 0 019-9"></path>
                        </svg>
                        zhili.wanli.ai
                    </a>
                </div>
            </div>

            <!-- æ–‡ç« æ ‡ç­¾ -->
            <div class="mt-8 pt-8 border-t border-gray-200">
                <div class="flex flex-wrap gap-2">
                    <span class="tag">#æˆæœ¬ä¼˜åŒ–</span>
                    <span class="tag">#AIåº”ç”¨</span>
                    <span class="tag">#GPT-4</span>
                    <span class="tag">#å¼€æºæ¨¡å‹</span>
                    <span class="tag">#æ€§èƒ½ä¼˜åŒ–</span>
                </div>
            </div>

            <!-- è¿”å›åšå®¢åˆ—è¡¨ -->
            <div class="text-center mt-12">
                <a href="/blog/" class="inline-flex items-center px-6 py-3 bg-white border border-gray-300 rounded-lg hover:bg-gray-50 hover:border-gray-400 transition text-gray-700 font-medium">
                    <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 19l-7-7m0 0l7-7m-7 7h18"></path>
                    </svg>
                    è¿”å›åšå®¢åˆ—è¡¨
                </a>
            </div>

        </div>
    </main>

    <!-- é¡µè„š -->
    <footer class="bg-white border-t border-gray-200 mt-20">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
            <div class="text-center text-gray-500 text-sm">
                <p>&copy; 2024 åŒ—äº¬æ™ºç†ç§‘æŠ€æœ‰é™å…¬å¸ |
                    <a href="/" class="hover:text-blue-600">è¿”å›é¦–é¡µ</a> |
                    <a href="mailto:wuning@wanli.ai" class="hover:text-blue-600">è”ç³»æˆ‘ä»¬</a>
                </p>
            </div>
        </div>
    </footer>

    <!-- ç»“æ„åŒ–æ•°æ® - Article -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "AIåº”ç”¨æˆæœ¬ä¼˜åŒ–å®Œå…¨æŒ‡å—ï¼šä»æ¯æœˆ$5000é™è‡³$800çš„å®æˆ˜ç»éªŒ",
      "description": "åˆ†äº«çœŸå®é¡¹ç›®ä¸­å°†AIåº”ç”¨æˆæœ¬ä»æ¯æœˆ$5000é™è‡³$800çš„å®Œæ•´ä¼˜åŒ–ç­–ç•¥ï¼Œæ¶µç›–æ¨¡å‹é€‰å‹ã€Promptä¼˜åŒ–ã€ç¼“å­˜ç­–ç•¥ã€æœ¬åœ°åŒ–éƒ¨ç½²ç­‰å¤šä¸ªç»´åº¦",
      "image": "https://zhili.wanli.ai/og-image.jpg",
      "datePublished": "2024-12-31T10:00:00+08:00",
      "dateModified": "2024-12-31T10:00:00+08:00",
      "author": {
        "@type": "Organization",
        "name": "æ™ºç†ç§‘æŠ€æŠ€æœ¯å›¢é˜Ÿ"
      },
      "publisher": {
        "@type": "Organization",
        "name": "åŒ—äº¬æ™ºç†ç§‘æŠ€æœ‰é™å…¬å¸",
        "logo": {
          "@type": "ImageObject",
          "url": "https://zhili.wanli.ai/og-image.jpg"
        }
      },
      "articleSection": "AIåº”ç”¨å¼€å‘",
      "keywords": ["æˆæœ¬ä¼˜åŒ–","AIåº”ç”¨","GPT-4","å¼€æºæ¨¡å‹","æ€§èƒ½ä¼˜åŒ–"],
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://zhili.wanli.ai/blog/posts/ai-cost-optimization-guide.html"
      }
    }
    </script>

</body>
</html>